{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6de6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c603c304",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a7a309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='data/edition_translation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4bd39c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data import\n",
    "train_data_ecco=pd.read_csv(path+'ecco_monolingual_train.csv')\n",
    "train_data_ecco['ecco_full_title']=train_data_ecco['ecco_full_title'].str.translate(str.maketrans(\"\", \"\", string.punctuation)).str.lower()\n",
    "test_data_ecco=pd.read_csv(path+'ecco_monolingual_test.csv')\n",
    "test_data_ecco['ecco_full_title']=test_data_ecco['ecco_full_title'].str.translate(str.maketrans(\"\", \"\", string.punctuation)).str.lower()\n",
    "train_data_caa=pd.read_csv(path+'caa_monolingual_train.csv')\n",
    "train_data_caa['title']=train_data_caa['title'].str.translate(str.maketrans(\"\", \"\", string.punctuation)).str.lower()\n",
    "test_data_caa=pd.read_csv(path+'caa_monolingual_test.csv')\n",
    "test_data_caa['title']=test_data_caa['title'].str.translate(str.maketrans(\"\", \"\", string.punctuation)).str.lower()\n",
    "balanced_train_data_caa=pd.read_csv(path+'caa_monolingual_balanced_train.csv')\n",
    "balanced_train_data_caa['title']=balanced_train_data_caa['title'].str.translate(str.maketrans(\"\", \"\", string.punctuation)).str.lower()\n",
    "balanced_test_data_caa=pd.read_csv(path+'caa_monolingual_balanced_test.csv')\n",
    "balanced_test_data_caa['title']=balanced_test_data_caa['title'].str.translate(str.maketrans(\"\", \"\", string.punctuation)).str.lower()\n",
    "combined_train_data=pd.read_csv(path+'combined_monolingual_train.csv')\n",
    "combined_train_data['title']=combined_train_data['title'].str.translate(str.maketrans(\"\", \"\", string.punctuation)).str.lower()\n",
    "combined_test_data=pd.read_csv(path+'combined_monolingual_test.csv')\n",
    "combined_test_data['title']=combined_test_data['title'].str.translate(str.maketrans(\"\", \"\", string.punctuation)).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ff25219",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined=pd.concat([combined_train_data,combined_test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52a2d97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>monolingual</th>\n",
       "      <th>multilingual</th>\n",
       "      <th>monolingual_translations</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3421</td>\n",
       "      <td>4115</td>\n",
       "      <td>1127</td>\n",
       "      <td>nicolai vernvlæi ottocarvs bohemiæ rex sev reb...</td>\n",
       "      <td>9911760850101488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>caa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5891</td>\n",
       "      <td>8689</td>\n",
       "      <td>2234</td>\n",
       "      <td>pars secunda tractatvs de jure devolutionis in...</td>\n",
       "      <td>9992391009101488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>caa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>961</td>\n",
       "      <td>985</td>\n",
       "      <td>1879</td>\n",
       "      <td>joannis ludovici vives colloquia alioqui latin...</td>\n",
       "      <td>998537850101488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>caa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4966</td>\n",
       "      <td>6781</td>\n",
       "      <td>679</td>\n",
       "      <td>oratio fvnebris in obitvm  matthiæ hovii archi...</td>\n",
       "      <td>9978909880101488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>caa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5479</td>\n",
       "      <td>7790</td>\n",
       "      <td>2740</td>\n",
       "      <td>ivstificatio sev defensio censvræ facvltatis s...</td>\n",
       "      <td>9935323420101488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>caa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>4350</td>\n",
       "      <td>5628</td>\n",
       "      <td>2497</td>\n",
       "      <td>philippus iv</td>\n",
       "      <td>9983928540101488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>caa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>3126</td>\n",
       "      <td>3698</td>\n",
       "      <td>98</td>\n",
       "      <td>benedicti xiv  commentarius de sacrosancto mis...</td>\n",
       "      <td>992119560101488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>caa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>323</td>\n",
       "      <td>328</td>\n",
       "      <td>2827</td>\n",
       "      <td>de lipsii latinitate vt ipsimet antiquarii ant...</td>\n",
       "      <td>9911797690101488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>caa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>3509</td>\n",
       "      <td>4235</td>\n",
       "      <td>1811</td>\n",
       "      <td>æsops fables with his life and morals and rema...</td>\n",
       "      <td>63801300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ecco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>4905</td>\n",
       "      <td>6653</td>\n",
       "      <td>1827</td>\n",
       "      <td>ivsti lipsii von der bestendigkeit zwey bücher...</td>\n",
       "      <td>9992199891601488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>caa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5228 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  level_0  index  \\\n",
       "0           3421     4115   1127   \n",
       "1           5891     8689   2234   \n",
       "2            961      985   1879   \n",
       "3           4966     6781    679   \n",
       "4           5479     7790   2740   \n",
       "...          ...      ...    ...   \n",
       "1041        4350     5628   2497   \n",
       "1042        3126     3698     98   \n",
       "1043         323      328   2827   \n",
       "1044        3509     4235   1811   \n",
       "1045        4905     6653   1827   \n",
       "\n",
       "                                                  title                id  \\\n",
       "0     nicolai vernvlæi ottocarvs bohemiæ rex sev reb...  9911760850101488   \n",
       "1     pars secunda tractatvs de jure devolutionis in...  9992391009101488   \n",
       "2     joannis ludovici vives colloquia alioqui latin...   998537850101488   \n",
       "3     oratio fvnebris in obitvm  matthiæ hovii archi...  9978909880101488   \n",
       "4     ivstificatio sev defensio censvræ facvltatis s...  9935323420101488   \n",
       "...                                                 ...               ...   \n",
       "1041                                       philippus iv  9983928540101488   \n",
       "1042  benedicti xiv  commentarius de sacrosancto mis...   992119560101488   \n",
       "1043  de lipsii latinitate vt ipsimet antiquarii ant...  9911797690101488   \n",
       "1044  æsops fables with his life and morals and rema...          63801300   \n",
       "1045  ivsti lipsii von der bestendigkeit zwey bücher...  9992199891601488   \n",
       "\n",
       "      monolingual  multilingual  monolingual_translations source  \n",
       "0               1             0                         0    caa  \n",
       "1               1             0                         0    caa  \n",
       "2               1             0                         0    caa  \n",
       "3               1             0                         0    caa  \n",
       "4               1             0                         0    caa  \n",
       "...           ...           ...                       ...    ...  \n",
       "1041            1             0                         0    caa  \n",
       "1042            1             0                         0    caa  \n",
       "1043            1             0                         0    caa  \n",
       "1044            1             0                         1   ecco  \n",
       "1045            1             0                         1    caa  \n",
       "\n",
       "[5228 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[(combined['monolingual']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19671b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate test and train data\n",
    "combined_test_train = pd.concat([combined_test_data, combined_train_data])\n",
    "\n",
    "# Tokenize the text and remove punctuation\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation using string.punctuation\n",
    "    cleaned_text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    return [word for word in cleaned_text.lower().split()]\n",
    "\n",
    "tokens_cleaned = combined_test_train['title'].apply(preprocess_text)\n",
    "\n",
    "# Calculate word frequencies\n",
    "word_counts = Counter(word for sublist in tokens_cleaned for word in sublist)\n",
    "\n",
    "# Initialize presence_counts dictionary\n",
    "presence_counts = {}\n",
    "\n",
    "# Check if the word is not in word_counts and calculate presence count\n",
    "for sublist in tokens_cleaned:\n",
    "    for word in sublist:\n",
    "        if word not in word_counts:\n",
    "            presence_counts[word] = len(combined_test_train[combined_test_train['title'].str.lower().apply(lambda x: word in x)])\n",
    "\n",
    "# Filter based on frequency and proportion\n",
    "n_titles = len(combined_test_train)\n",
    "common_vocabulary = [word for word, count in word_counts.items() if 1 < count <= 0.8 * n_titles and word not in presence_counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac593774",
   "metadata": {},
   "source": [
    "# Train on ECCO, test on ECCO for original vs translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99a04cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data_ecco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90aa0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"estc_id\"\n",
    "source_field=\"ecco_full_title\"\n",
    "target_field=\"monolingual_translations\"\n",
    "x_train=train_data[['estc_id', 'ecco_full_title']]\n",
    "y_train=train_data[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bca19591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.962):\n",
      "{'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'tfidf__ngram_range': (1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='squared_hinge' is not supported, Parameters: penalty=None, loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.96034133\n",
      " 0.96034133 0.96034133 0.65934892 0.65934892        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96175726 0.96175726 0.96175726 0.46831065 0.53262161\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline to search for the best combination of TFidf vectorizer and logistic regression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(vocabulary=common_vocabulary, lowercase=True)),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "# Parameters of pipelines can be set using '__' separated parameter names:\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3)],\n",
    "    'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "}\n",
    "search = GridSearchCV(pipeline, param_grid)\n",
    "search.fit(x_train[source_field], y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "272c357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf__class_weight=None\n",
    "clf__penalty= 'l2' \n",
    "tfidf__ngram_range= (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3502ab",
   "metadata": {},
   "source": [
    "### I now do the prediction based on the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91549de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformer = TfidfVectorizer(vocabulary=common_vocabulary, ngram_range=tfidf__ngram_range, lowercase=True, max_features=150000)\n",
    "clf= LinearSVC(class_weight=clf__class_weight, penalty=clf__penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40259183",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_data_ecco[[id_field, source_field]]\n",
    "y_test=test_data_ecco[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8435c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = text_transformer.fit_transform(x_train[source_field])\n",
    "X_test_text = text_transformer.transform(x_test[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a3984c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_text, y_train)\n",
    "test_preds = clf.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6aa8fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       128\n",
      "           1       0.95      0.98      0.97       225\n",
      "\n",
      "    accuracy                           0.96       353\n",
      "   macro avg       0.96      0.95      0.95       353\n",
      "weighted avg       0.96      0.96      0.96       353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca6cdd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9575070821529745"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf0c0a",
   "metadata": {},
   "source": [
    "## I now do the prediction on caa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fc719fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"RecordID\"\n",
    "source_field=\"title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da04294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_data_caa[[id_field, source_field]]\n",
    "y_test=test_data_caa[target_field]\n",
    "x_test_balanced=balanced_test_data_caa[[id_field, source_field]]\n",
    "y_test_balanced=balanced_test_data_caa[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94dd4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_caa = text_transformer.transform(x_test[source_field])\n",
    "X_balanced_test_caa=text_transformer.transform(x_test_balanced[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e1a5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_caa = clf.predict(X_test_caa)\n",
    "y_preds_balanced=clf.predict(X_balanced_test_caa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2603d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.65      0.79       663\n",
      "           1       0.10      0.84      0.18        31\n",
      "\n",
      "    accuracy                           0.66       694\n",
      "   macro avg       0.54      0.75      0.48       694\n",
      "weighted avg       0.95      0.66      0.76       694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_caa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49a7c8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.60      0.73        72\n",
      "           1       0.51      0.91      0.65        33\n",
      "\n",
      "    accuracy                           0.70       105\n",
      "   macro avg       0.72      0.75      0.69       105\n",
      "weighted avg       0.80      0.70      0.70       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_balanced, y_preds_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a87f070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.659942363112392"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds_caa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce30a311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6952380952380952"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_balanced, y_preds_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25223ae6",
   "metadata": {},
   "source": [
    "### I test on the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab2abbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"id\"\n",
    "source_field=\"title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6080759",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=combined_test_data[[id_field, source_field]]\n",
    "y_test=combined_test_data[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "967b50ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = text_transformer.transform(x_test[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f57d8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84e44dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81       800\n",
      "           1       0.49      0.96      0.65       246\n",
      "\n",
      "    accuracy                           0.75      1046\n",
      "   macro avg       0.74      0.83      0.73      1046\n",
      "weighted avg       0.87      0.75      0.77      1046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "877955d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7523900573613767"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6687b55c",
   "metadata": {},
   "source": [
    "### I train and predict on CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de667a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data_caa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "794e6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"RecordID\"\n",
    "source_field=\"title\"\n",
    "target_field=\"monolingual_translations\"\n",
    "x_train=train_data[[id_field, source_field]]\n",
    "y_train=train_data[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89943e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.959):\n",
      "{'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'tfidf__ngram_range': (1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='squared_hinge' is not supported, Parameters: penalty=None, loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.95562689\n",
      " 0.95562689 0.95562689 0.94805217 0.94805217        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.95851172 0.95851172 0.95851172 0.58985397 0.2310092\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline to search for the best combination of TFidf vectorizer and logistic regression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(vocabulary=common_vocabulary, lowercase=True)),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "# Parameters of pipelines can be set using '__' separated parameter names:\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3)],\n",
    "    'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "}\n",
    "search = GridSearchCV(pipeline, param_grid)\n",
    "search.fit(x_train[source_field], y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f99d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf__class_weight='balanced'\n",
    "clf__penalty= 'l2' \n",
    "tfidf__ngram_range= (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a7400f",
   "metadata": {},
   "source": [
    "## I now do the prediction based on the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9fc670cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformer = TfidfVectorizer(vocabulary=common_vocabulary, ngram_range=tfidf__ngram_range, lowercase=True, max_features=150000)\n",
    "clf= LinearSVC(class_weight=clf__class_weight, penalty=clf__penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b7820a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_data_caa[[id_field, source_field]]\n",
    "y_test=test_data_caa[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38e0f0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(class_weight='balanced')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text = text_transformer.fit_transform(x_train[source_field])\n",
    "X_test_text = text_transformer.transform(x_test[source_field])\n",
    "clf.fit(X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31645a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_data_caa[[id_field, source_field]]\n",
    "y_test=test_data_caa[target_field]\n",
    "x_test_balanced=balanced_test_data_caa[[id_field, source_field]]\n",
    "y_test_balanced=balanced_test_data_caa[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4e3f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_caa = text_transformer.transform(x_test[source_field])\n",
    "X_balanced_test_caa=text_transformer.transform(x_test_balanced[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa446a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_caa = clf.predict(X_test_caa)\n",
    "y_preds_balanced=clf.predict(X_balanced_test_caa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de97ee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       663\n",
      "           1       0.55      0.52      0.53        31\n",
      "\n",
      "    accuracy                           0.96       694\n",
      "   macro avg       0.76      0.75      0.76       694\n",
      "weighted avg       0.96      0.96      0.96       694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds_caa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5432210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        72\n",
      "           1       0.97      0.85      0.90        33\n",
      "\n",
      "    accuracy                           0.94       105\n",
      "   macro avg       0.95      0.92      0.93       105\n",
      "weighted avg       0.94      0.94      0.94       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_balanced, y_preds_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34f58a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9596541786743515"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds_caa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9cca8e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9428571428571428"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_balanced, y_preds_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e45e5d",
   "metadata": {},
   "source": [
    "## I test on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07d222ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"estc_id\"\n",
    "source_field=\"ecco_full_title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bbbe61b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_data_ecco[[id_field, source_field]]\n",
    "y_test=test_data_ecco[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af2ee809",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = text_transformer.transform(x_test[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f7b7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=clf.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7500a017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a9089b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.98      0.56       128\n",
      "           1       0.91      0.13      0.23       225\n",
      "\n",
      "    accuracy                           0.44       353\n",
      "   macro avg       0.65      0.55      0.40       353\n",
      "weighted avg       0.72      0.44      0.35       353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4dfc559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43909348441926344"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d1ea6",
   "metadata": {},
   "source": [
    "## I test on the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3075fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"id\"\n",
    "source_field=\"title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60fa2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=combined_test_data[[id_field, source_field]]\n",
    "y_test=combined_test_data[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe2c2c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = text_transformer.transform(x_test[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc5b2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a56151cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89       800\n",
      "           1       0.90      0.26      0.40       246\n",
      "\n",
      "    accuracy                           0.82      1046\n",
      "   macro avg       0.86      0.63      0.65      1046\n",
      "weighted avg       0.83      0.82      0.78      1046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd2365f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8193116634799236"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56734231",
   "metadata": {},
   "source": [
    "# I train on both and test on each one singularly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "70d4d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=combined_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb67de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"id\"\n",
    "source_field=\"title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e51c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train_data[[id_field,source_field]]\n",
    "y_train=train_data[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9115555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.954):\n",
      "{'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'tfidf__ngram_range': (1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='squared_hinge' is not supported, Parameters: penalty=None, loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.95026496\n",
      " 0.95026496 0.95026496 0.74055467 0.74055467        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.95361596 0.95361596 0.95361596 0.64425837 0.25944533\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline to search for the best combination of TFidf vectorizer and logistic regression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(vocabulary=common_vocabulary, lowercase=True)),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "# Parameters of pipelines can be set using '__' separated parameter names:\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3)],\n",
    "    'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "}\n",
    "search = GridSearchCV(pipeline, param_grid)\n",
    "search.fit(x_train[source_field], y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2905dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf__class_weight='balanced'\n",
    "clf__penalty= 'l2' \n",
    "tfidf__ngram_range= (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fee9ce",
   "metadata": {},
   "source": [
    "## I now do the prediction based on the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd61f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformer = TfidfVectorizer(vocabulary=common_vocabulary, ngram_range=tfidf__ngram_range, lowercase=True, max_features=150000)\n",
    "clf= LinearSVC(class_weight=clf__class_weight, penalty=clf__penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eedab33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=combined_test_data[[id_field, source_field]]\n",
    "y_test=combined_test_data[[target_field, 'source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e46d579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = text_transformer.fit_transform(x_train[source_field])\n",
    "X_test_text = text_transformer.transform(x_test[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d3b4309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_text, y_train)\n",
    "test_preds = clf.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1a9ed21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       800\n",
      "           1       0.93      0.89      0.91       246\n",
      "\n",
      "    accuracy                           0.96      1046\n",
      "   macro avg       0.95      0.93      0.94      1046\n",
      "weighted avg       0.96      0.96      0.96      1046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[target_field], test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a7d1b767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579349904397706"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[target_field], test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852354e3",
   "metadata": {},
   "source": [
    "## I test on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "008c8508",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"estc_id\"\n",
    "source_field=\"ecco_full_title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ae4080c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_data_ecco[[id_field, source_field]]\n",
    "y_test=test_data_ecco[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "704f49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = text_transformer.transform(x_test[source_field])\n",
    "test_preds=clf.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a768c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       128\n",
      "           1       0.96      0.99      0.97       225\n",
      "\n",
      "    accuracy                           0.96       353\n",
      "   macro avg       0.97      0.95      0.96       353\n",
      "weighted avg       0.96      0.96      0.96       353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1832116a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631728045325779"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9301aa58",
   "metadata": {},
   "source": [
    "## I test on unbalanced caa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a6533d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"RecordID\"\n",
    "source_field=\"title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "62874ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_data_caa[[id_field, source_field]]\n",
    "y_test=test_data_caa[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "440be501",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = text_transformer.transform(x_test[source_field])\n",
    "test_preds=clf.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ed808547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       663\n",
      "           1       0.93      0.90      0.92        31\n",
      "\n",
      "    accuracy                           0.99       694\n",
      "   macro avg       0.96      0.95      0.96       694\n",
      "weighted avg       0.99      0.99      0.99       694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ddc56e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927953890489913"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee76a7a",
   "metadata": {},
   "source": [
    "## I test on balanced CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b5351227",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"RecordID\"\n",
    "source_field=\"title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "59925647",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=balanced_test_data_caa[[id_field, source_field]]\n",
    "y_test=balanced_test_data_caa[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef4988bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = text_transformer.transform(x_test[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "494d4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=clf.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0de1fbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        72\n",
      "           1       0.97      0.97      0.97        33\n",
      "\n",
      "    accuracy                           0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "16322113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9809523809523809"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b479d0",
   "metadata": {},
   "source": [
    "## I now redo the pipeline for CAA by sampling the data for more balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a2c280d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=balanced_train_data_caa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4300d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"RecordID\"\n",
    "source_field=\"title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cc561e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train_data[[id_field, source_field]]\n",
    "y_train=train_data[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "15993383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.848):\n",
      "{'clf__class_weight': None, 'clf__penalty': 'l2', 'tfidf__ngram_range': (1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='elasticnet' and loss='squared_hinge' is not supported, Parameters: penalty='elasticnet', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='squared_hinge' is not supported, Parameters: penalty=None, loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\u0140177\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.84761905\n",
      " 0.84761905 0.84761905 0.66190476 0.66190476        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.84761905 0.84761905 0.84761905 0.4047619  0.5952381\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline to search for the best combination of TFidf vectorizer and logistic regression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(vocabulary=common_vocabulary, lowercase=True)),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "# Parameters of pipelines can be set using '__' separated parameter names:\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3)],\n",
    "    'clf__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "}\n",
    "search = GridSearchCV(pipeline, param_grid)\n",
    "search.fit(x_train[source_field], y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "866c2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf__class_weight=None\n",
    "clf__penalty= 'l2' \n",
    "tfidf__ngram_range= (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f12c5",
   "metadata": {},
   "source": [
    "## I now do the prediction based on the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d0c886ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformer = TfidfVectorizer(vocabulary=common_vocabulary, ngram_range=tfidf__ngram_range, lowercase=True, max_features=150000)\n",
    "clf= LinearSVC(class_weight=clf__class_weight, penalty=clf__penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1a90835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=balanced_test_data_caa[[id_field, source_field]]\n",
    "y_test=balanced_test_data_caa[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8e825036",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = text_transformer.fit_transform(x_train[source_field])\n",
    "X_test_text = text_transformer.transform(x_test[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4b3241bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "37a32239",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "04666818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90        72\n",
      "           1       0.78      0.76      0.77        33\n",
      "\n",
      "    accuracy                           0.86       105\n",
      "   macro avg       0.84      0.83      0.83       105\n",
      "weighted avg       0.86      0.86      0.86       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "082d8fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f274dc17",
   "metadata": {},
   "source": [
    "## I test on unbalanced caa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "65aefd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"RecordID\"\n",
    "source_field=\"title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e085f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_data_caa[[id_field, source_field]]\n",
    "y_test=test_data_caa[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2be92f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = text_transformer.transform(x_test[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "55fd9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=clf.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "322d0a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       663\n",
      "           1       0.43      0.97      0.60        31\n",
      "\n",
      "    accuracy                           0.94       694\n",
      "   macro avg       0.72      0.95      0.78       694\n",
      "weighted avg       0.97      0.94      0.95       694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d4d5afb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9423631123919308"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5490d39",
   "metadata": {},
   "source": [
    "## I test on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a222c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_field=\"estc_id\"\n",
    "source_field=\"ecco_full_title\"\n",
    "target_field=\"monolingual_translations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c56197ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test_data_ecco[[id_field, source_field]]\n",
    "y_test=test_data_ecco[target_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2006940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = text_transformer.transform(x_test[source_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cfae5bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=clf.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d65b658c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72       128\n",
      "           1       0.92      0.66      0.77       225\n",
      "\n",
      "    accuracy                           0.75       353\n",
      "   macro avg       0.76      0.78      0.74       353\n",
      "weighted avg       0.80      0.75      0.75       353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "23acd825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7450424929178471"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e616ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787a424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
