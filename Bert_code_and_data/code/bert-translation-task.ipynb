{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c15355-92cc-472c-bb28-0c59f5fa452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset, load_dataset, ClassLabel, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b84de8-3ca7-42c5-88ec-a649b3346dee",
   "metadata": {},
   "source": [
    "Import training datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73b2b50-daf4-47e4-aeaa-e531f8502d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecco_train_df = pd.read_csv('../data/translation-task-data/ecco_monolingual_train_no_dupl.csv')\n",
    "ecco_test_df = pd.read_csv('../data/translation-task-data/ecco_monolingual_test_no_dupl.csv')\n",
    "\n",
    "ecco_train_df.rename(columns={\"monolingual_translations\": \"label\", \"ecco_full_title\": \"text\"}, inplace=True)\n",
    "ecco_test_df.rename(columns={\"monolingual_translations\": \"label\", \"ecco_full_title\": \"text\"}, inplace=True)\n",
    "\n",
    "ecco_train_dataset = Dataset.from_pandas(ecco_train_df)\n",
    "ecco_test_dataset = Dataset.from_pandas(ecco_test_df)\n",
    "\n",
    "ecco = DatasetDict({\"train\": ecco_train_dataset,\n",
    "                       \"test\": ecco_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4cd8a72-6eab-4729-b137-1f4044427714",
   "metadata": {},
   "outputs": [],
   "source": [
    "caa_train_df = pd.read_csv('../data/translation-task-data/caa_monolingual_train.csv')\n",
    "caa_test_df = pd.read_csv('../data/translation-task-data/caa_monolingual_test.csv')\n",
    "\n",
    "caa_train_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "caa_test_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "caa_train_dataset = Dataset.from_pandas(caa_train_df)\n",
    "caa_test_dataset = Dataset.from_pandas(caa_test_df)\n",
    "\n",
    "caa = DatasetDict({\"train\": caa_train_dataset,\n",
    "                       \"test\": caa_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5299ed-65ac-4f18-af49-34628bcf9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_caa_train_df = pd.read_csv('../data/translation-task-data/caa_monolingual_balanced_train.csv')\n",
    "balanced_caa_test_df = pd.read_csv('../data/translation-task-data/caa_monolingual_balanced_test.csv')\n",
    "\n",
    "balanced_caa_train_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "balanced_caa_test_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "balanced_caa_train_dataset = Dataset.from_pandas(balanced_caa_train_df)\n",
    "balanced_caa_test_dataset = Dataset.from_pandas(balanced_caa_test_df)\n",
    "\n",
    "balanced_caa = DatasetDict({\"train\": balanced_caa_train_dataset,\n",
    "                       \"test\": balanced_caa_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df72979-2a52-4e03-b402-6bf3dcbc21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_df = pd.read_csv('../data/translation-task-data/combined_monolingual_train_no_dupl.csv')\n",
    "combined_test_df = pd.read_csv('../data/translation-task-data/combined_monolingual_test_no_dupl.csv')\n",
    "\n",
    "combined_train_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "combined_test_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "combined_train_dataset = Dataset.from_pandas(combined_train_df)\n",
    "combined_test_dataset = Dataset.from_pandas(combined_test_df)\n",
    "\n",
    "combined = DatasetDict({\"train\": combined_train_dataset,\n",
    "                       \"test\": combined_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395d97e7-7764-475c-90bb-d032aae7441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_balanced_caa_train_df = pd.read_csv('../data/translation-task-data/balanced_data_both_language_train_df.csv')\n",
    "combined_balanced_caa_test_df = pd.read_csv('../data/translation-task-data/balanced_data_both_language_test_df.csv')\n",
    "\n",
    "combined_balanced_caa_train_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "combined_balanced_caa_test_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "combined_balanced_caa_train_dataset = Dataset.from_pandas(combined_balanced_caa_train_df)\n",
    "combined_balanced_caa_test_dataset = Dataset.from_pandas(combined_balanced_caa_test_df)\n",
    "\n",
    "combined_balanced_caa = DatasetDict({\"train\": combined_balanced_caa_train_dataset,\n",
    "                       \"test\": combined_balanced_caa_test_dataset,})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b7e701-d22b-4f44-a18e-a5e7a223ca2a",
   "metadata": {},
   "source": [
    "# Trained on CAA - Standard BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "097ab9b8-3592-4168-af9c-3a8f6c8cb445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630d24b6-63b5-475e-9576-c8df03709e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "620a3838-f8dc-4081-86f3-e91cddfd6398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d6562f3aa74cd1b8c080965db80a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2772 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d330bd23be246438059fd9b6d13307a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/694 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_caa = caa.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01f8e2b3-e9e7-47b0-877e-d6201e3854f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f4110e4-8c0d-4340-a90c-56534ca261e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc35000a-6c3a-4208-916f-da8de46403b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85fe3f3f-66bb-446d-9983-130c8c6333b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained( \"google-bert/bert-base-multilingual-cased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b8ef5f2-e186-4b94-94ee-a91561097be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5de3d06-6260-4dcf-b3f2-92dfa7aaae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='870' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [870/870 03:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.101781</td>\n",
       "      <td>0.956772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.076747</td>\n",
       "      <td>0.976945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.095643</td>\n",
       "      <td>0.976945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.089424</td>\n",
       "      <td>0.979827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.109641</td>\n",
       "      <td>0.975504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results_mono\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_caa[\"train\"],\n",
    "    eval_dataset=tokenized_caa[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bert_models_translations/caa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d643f8c-9820-4d56-a302-361a6c82794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert_models_translations/caa/', local_files_only=True)\n",
    "\n",
    "model = model.to('cuda')\n",
    "\n",
    "trainer = Trainer(model=model)\n",
    "\n",
    "trainer.model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eac04df0-a407-4381-a047-bf37379d5f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcca0c078e64dfaa34f2c2da4e2879a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/694 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=max_length)\n",
    "\n",
    "new_text_list = caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = caa_test_df[\"label\"]\n",
    "\n",
    "eval_results_caa = classification_report(true_labels, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c945d9-61be-47b3-ad38-4df16c337587",
   "metadata": {},
   "source": [
    "# tested on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ee32ed7-9307-49d8-a700-df5a81584e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a287695079a0482689d14da8b00adc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = ecco_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = ecco_test_df[\"label\"]\n",
    "\n",
    "caa_ecco_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32fcf2-f00b-43d5-aac2-bf00679360b8",
   "metadata": {},
   "source": [
    "# Tested on combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09593c22-0739-4620-a1ba-8fb7b613c848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e746be74101a4507888fe5a3e04c0389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=max_length)\n",
    "\n",
    "\n",
    "new_text_list = combined_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_test_df[\"label\"]\n",
    "\n",
    "caa_combined_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486b718-dd4f-4ca7-8d93-0ae4201958f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac1b4336-fc35-4bb9-b21c-19fbe084816e",
   "metadata": {},
   "source": [
    "# tested on caa balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87486d3b-5464-4ba5-bfb8-cae4e50010ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ae0a8eaafe48468530fe67a67f4373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = balanced_caa_test_df[\"label\"]\n",
    "\n",
    "caa_caa_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8886f83c-f489-4644-86f7-18db4f85c2b1",
   "metadata": {},
   "source": [
    "# Trained on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c776a8c-a6a0-4340-b45c-cc7acb94ced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-multilingual-cased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40a9464-4d55-435c-b255-73ac375cd30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61e26195217427eb45f3721f698d370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1412 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ee83030ee1456f805904680bceb84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ecco = ecco.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ca32e14-c1d7-4e8f-96e1-5080d23a4c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='445' max='445' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [445/445 01:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241524</td>\n",
       "      <td>0.943343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.224832</td>\n",
       "      <td>0.943343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.202349</td>\n",
       "      <td>0.951841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.193637</td>\n",
       "      <td>0.957507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.196267</td>\n",
       "      <td>0.957507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ecco[\"train\"],\n",
    "    eval_dataset=tokenized_ecco[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bert_models_translations/ecco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58af7c6b-d47e-407f-94e5-a67d34a7731d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b42961bfe347899ecfc08fbe86e489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = ecco_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = ecco_test_df[\"label\"]\n",
    "\n",
    "ecco_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6473401-613d-4b47-a6cd-7c65d6363b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9747899159663865,\n",
       "  'recall': 0.90625,\n",
       "  'f1-score': 0.9392712550607287,\n",
       "  'support': 128.0},\n",
       " '1': {'precision': 0.9487179487179487,\n",
       "  'recall': 0.9866666666666667,\n",
       "  'f1-score': 0.9673202614379085,\n",
       "  'support': 225.0},\n",
       " 'accuracy': 0.9575070821529745,\n",
       " 'macro avg': {'precision': 0.9617539323421676,\n",
       "  'recall': 0.9464583333333334,\n",
       "  'f1-score': 0.9532957582493187,\n",
       "  'support': 353.0},\n",
       " 'weighted avg': {'precision': 0.9581718065304135,\n",
       "  'recall': 0.9575070821529745,\n",
       "  'f1-score': 0.9571495169158716,\n",
       "  'support': 353.0}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739121ee-223f-4733-a6b3-0b1e34cdf969",
   "metadata": {},
   "source": [
    "# Tested on CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "903f0206-8d3e-44a5-bd18-981bf313a471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7902f73d344c41e7a5a28270978c3278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/694 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = caa_test_df[\"label\"]\n",
    "\n",
    "ecco_caa_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778575f7-c3d3-491e-a836-6dfe83326e76",
   "metadata": {},
   "source": [
    "# Tested on combined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac8d62d7-54fe-4962-ab18-d62ecec29dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f45c22e05194fc7af98f3dd3183e23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_test_df[\"label\"]\n",
    "\n",
    "ecco_combined_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b24b4e-f52e-4454-b44d-2465d1124bab",
   "metadata": {},
   "source": [
    "# Tested on balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f2cc496-4692-417e-80c0-90220ed20508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5502979b325d4fd395b4ca16aa19b52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = balanced_caa_test_df[\"label\"]\n",
    "\n",
    "ecco_caa_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198b054-35d5-46fc-8ddc-86519b78cbd0",
   "metadata": {},
   "source": [
    "# Trained on both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10f8f8ca-13ac-42ab-b857-f3ddb9361f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-multilingual-cased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a049bca-76c8-4fe8-8e6a-d779840db5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5dd920e90a46b6a48b0fdb04a61b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5616 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8513dd758c8743c780d487721c70686a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_combined = combined.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf8b4bdc-d1ac-460b-8ae3-b399103c9443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1755' max='1755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1755/1755 07:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.135720</td>\n",
       "      <td>0.960826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.124386</td>\n",
       "      <td>0.973647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.123403</td>\n",
       "      <td>0.975071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.142816</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.130325</td>\n",
       "      <td>0.972934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_combined[\"train\"],\n",
    "    eval_dataset=tokenized_combined[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bert_models_translations/combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af900a60-f643-491b-a920-6684ef001e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5192269ea2fd4b92811a9bb47efe1032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_test_df[\"label\"]\n",
    "\n",
    "combined_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95745824-214a-4896-9961-6c666ce7658e",
   "metadata": {},
   "source": [
    "# Tested on CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "977e2a41-14cc-49d9-a6e3-9a55a844acaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d34645222cf49709aee1141169548a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/694 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = caa_test_df[\"label\"]\n",
    "\n",
    "combined_caa_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e7c1a-94b5-4330-82ab-2f4a038406cb",
   "metadata": {},
   "source": [
    "# Tested on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbd0fb6e-9f6c-492c-b7ee-4156a91296fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a852c8e3cd4066936f2c12014f3c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = ecco_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = ecco_test_df[\"label\"]\n",
    "\n",
    "combined_ecco_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec6327-8e15-4038-b22b-5c8380e22886",
   "metadata": {},
   "source": [
    "# Tested on CAA balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ad703ce-ab2d-42fe-afa5-defd0c9265e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e31a7dc2a34815b805fb4ce975c1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = balanced_caa_test_df[\"label\"]\n",
    "\n",
    "combined_caa_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4f258-00ec-4149-be64-f36dee5d4ea6",
   "metadata": {},
   "source": [
    "# Trained on CAA Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb685d50-7f1d-4d00-b389-5d37a09d37cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-multilingual-cased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5f675cd-a9b5-4f20-8d34-77253e386c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781ed99f043b4e148f97d4e07f7e2a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/420 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a711c3601c4e8b803ec63ca335d094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_balanced_caa = balanced_caa.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d4f47a2-d84f-455a-bea3-3993090fa3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:48, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.434376</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.354425</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.355673</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.477703</td>\n",
       "      <td>0.847619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.500385</td>\n",
       "      <td>0.876190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.618087</td>\n",
       "      <td>0.876190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.605793</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.625570</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_balanced_caa[\"train\"],\n",
    "    eval_dataset=tokenized_balanced_caa[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bert_models_translations/balanced_caa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c24496d-b20e-4f08-bb28-6047cfc3d60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0698c2e7097f4f61881f4350f2901bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = balanced_caa_test_df[\"label\"]\n",
    "\n",
    "caa_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7385a57-1707-4869-9201-43306e49d6c9",
   "metadata": {},
   "source": [
    "# Tested on CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6db0212e-b533-4ab0-91d6-33c153d6d5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad040892ed04954802d0aebc658dc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/694 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = caa_test_df[\"label\"]\n",
    "\n",
    "balanced_caa_caa_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d707d23-e4d4-4a5a-b48e-55c87b1aa8f8",
   "metadata": {},
   "source": [
    "# Tested on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70954744-3d8a-467a-b2d8-45e24d5e8fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c471477bad64ba592a06a614925cb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = ecco_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = ecco_test_df[\"label\"]\n",
    "\n",
    "balanced_caa_ecco_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e10e433-3253-4eb8-b688-6cafe17a7bf7",
   "metadata": {},
   "source": [
    "# Tested on combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9f35ef6-7f41-418b-9615-9f4447ebb69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f269800e1940838f22c0321bde36a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_test_df[\"label\"]\n",
    "\n",
    "balanced_caa_combined_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aad13f-e4ad-4844-9b1c-6b8132357d32",
   "metadata": {},
   "source": [
    "# Trained on combined_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52002238-8550-4f72-ba40-84d66f59ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-multilingual-cased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fd4d962-1b71-4117-b4d2-8ed4c16ed64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977e7615aadb40c1984ed2b1b59602a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309f9c95145d4aef9bbb78b7fa105e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_combined_balanced_caa = combined_balanced_caa.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da269a1c-52da-4a95-afb9-17828b3ab1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 00:32, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.395702</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.486099</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.395641</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.412061</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.531718</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.593832</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.779273</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_combined_balanced_caa[\"train\"],\n",
    "    eval_dataset=tokenized_combined_balanced_caa[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bert_models_translations/balanced_combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74b4d89f-3dd2-4c26-9366-b70f2a1c54e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05244f060c74d448288ad09f122a15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_balanced_caa_test_df[\"label\"]\n",
    "\n",
    "combined_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096efe6b-52fa-44bc-bd7a-ceb868641c77",
   "metadata": {},
   "source": [
    "# Tested on CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e211fd9-7b80-4299-9876-c0832b318b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b636a721f146f39e6d4ee2f8a9ed00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/694 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = caa_test_df[\"label\"]\n",
    "\n",
    "combined_balanced_caa_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26834d88-55b1-4398-99bd-e7d98d0f24ed",
   "metadata": {},
   "source": [
    "# Tested on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28844ce6-4548-4492-a382-a0cfe00c9530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4fdbb9056c4e669e4412c750265a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/353 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = ecco_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = ecco_test_df[\"label\"]\n",
    "\n",
    "combined_balanced_ecco_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136cadf8-b74e-4e02-80c7-93591653efb4",
   "metadata": {},
   "source": [
    "# Tested on combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c02581d-55bb-4e0c-aaa6-9a4820bfead9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8aecb2bb7f4d27a43ae6cba6754938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_test_df[\"label\"]\n",
    "\n",
    "combined_balanced_combined_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f08d653-efdc-461c-96eb-f493e1c26f5b",
   "metadata": {},
   "source": [
    "# Tested on CAA balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5977edb5-32b9-44bb-9583-453165c8bfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf230df9b3484df0a7c24a54d52aee0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_balanced_caa_test_df[\"label\"]\n",
    "\n",
    "combined_balanced_caa_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2ddd4b5-5061-4de0-bc2d-850ca4bb631f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DictName</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>0_precision</th>\n",
       "      <th>0_recall</th>\n",
       "      <th>0_f1-score</th>\n",
       "      <th>0_support</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_recall</th>\n",
       "      <th>1_f1-score</th>\n",
       "      <th>1_support</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>macro avg_support</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <th>weighted avg_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_results_caa</td>\n",
       "      <td>0.975504</td>\n",
       "      <td>0.987915</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.987170</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.864180</td>\n",
       "      <td>0.858664</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.975892</td>\n",
       "      <td>0.975504</td>\n",
       "      <td>0.975689</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caa_ecco_eval_results</td>\n",
       "      <td>0.745042</td>\n",
       "      <td>0.591346</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.778432</td>\n",
       "      <td>0.791580</td>\n",
       "      <td>0.744450</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.829840</td>\n",
       "      <td>0.745042</td>\n",
       "      <td>0.747832</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>caa_combined_eval_results</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.828837</td>\n",
       "      <td>0.994420</td>\n",
       "      <td>0.904110</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.984802</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>508.0</td>\n",
       "      <td>0.906820</td>\n",
       "      <td>0.816107</td>\n",
       "      <td>0.839152</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.885269</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.857103</td>\n",
       "      <td>1404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caa_caa_balanced_eval_results</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.972571</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971040</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ecco_eval_results</td>\n",
       "      <td>0.957507</td>\n",
       "      <td>0.974790</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.939271</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.967320</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.961754</td>\n",
       "      <td>0.946458</td>\n",
       "      <td>0.953296</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.958172</td>\n",
       "      <td>0.957507</td>\n",
       "      <td>0.957150</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ecco_caa_eval_results</td>\n",
       "      <td>0.655620</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.645551</td>\n",
       "      <td>0.781735</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.103053</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.546897</td>\n",
       "      <td>0.758259</td>\n",
       "      <td>0.483018</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.951089</td>\n",
       "      <td>0.655620</td>\n",
       "      <td>0.755049</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ecco_combined_eval_results</td>\n",
       "      <td>0.825499</td>\n",
       "      <td>0.990950</td>\n",
       "      <td>0.733259</td>\n",
       "      <td>0.842848</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.677463</td>\n",
       "      <td>0.988189</td>\n",
       "      <td>0.803843</td>\n",
       "      <td>508.0</td>\n",
       "      <td>0.834207</td>\n",
       "      <td>0.860724</td>\n",
       "      <td>0.823346</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.877523</td>\n",
       "      <td>0.825499</td>\n",
       "      <td>0.828735</td>\n",
       "      <td>1404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ecco_caa_balanced_eval_results</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.594059</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.680048</td>\n",
       "      <td>0.690657</td>\n",
       "      <td>0.608956</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.768771</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.614489</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>combined_eval_results</td>\n",
       "      <td>0.972934</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.972098</td>\n",
       "      <td>0.978652</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.974409</td>\n",
       "      <td>0.963035</td>\n",
       "      <td>508.0</td>\n",
       "      <td>0.968609</td>\n",
       "      <td>0.973254</td>\n",
       "      <td>0.970843</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.973220</td>\n",
       "      <td>0.972934</td>\n",
       "      <td>0.973001</td>\n",
       "      <td>1404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>combined_caa_eval_results</td>\n",
       "      <td>0.991354</td>\n",
       "      <td>0.995475</td>\n",
       "      <td>0.995475</td>\n",
       "      <td>0.995475</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.949350</td>\n",
       "      <td>0.949350</td>\n",
       "      <td>0.949350</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.991354</td>\n",
       "      <td>0.991354</td>\n",
       "      <td>0.991354</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>combined_ecco_eval_results</td>\n",
       "      <td>0.991501</td>\n",
       "      <td>0.984496</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.988327</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.995536</td>\n",
       "      <td>0.991111</td>\n",
       "      <td>0.993318</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.990016</td>\n",
       "      <td>0.991649</td>\n",
       "      <td>0.990823</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.991533</td>\n",
       "      <td>0.991501</td>\n",
       "      <td>0.991508</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>combined_caa_balanced_eval_results</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.954228</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.963910</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.961191</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>caa_balanced_eval_results</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.841492</td>\n",
       "      <td>0.869949</td>\n",
       "      <td>0.852053</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.877855</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.869324</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>balanced_caa_caa_eval_results</td>\n",
       "      <td>0.925072</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.959248</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.684370</td>\n",
       "      <td>0.945409</td>\n",
       "      <td>0.747481</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.970317</td>\n",
       "      <td>0.925072</td>\n",
       "      <td>0.940329</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>balanced_caa_ecco_eval_results</td>\n",
       "      <td>0.883853</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.867188</td>\n",
       "      <td>0.844106</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.922018</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.907449</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.872120</td>\n",
       "      <td>0.880260</td>\n",
       "      <td>0.875778</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.885832</td>\n",
       "      <td>0.883853</td>\n",
       "      <td>0.884481</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balanced_caa_combined_eval_results</td>\n",
       "      <td>0.913105</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.904018</td>\n",
       "      <td>0.929966</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.845878</td>\n",
       "      <td>0.929134</td>\n",
       "      <td>0.885553</td>\n",
       "      <td>508.0</td>\n",
       "      <td>0.901662</td>\n",
       "      <td>0.916576</td>\n",
       "      <td>0.907760</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.917079</td>\n",
       "      <td>0.913105</td>\n",
       "      <td>0.913896</td>\n",
       "      <td>1404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>combined_balanced_eval_results</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.750185</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.838877</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>combined_balanced_caa_eval_results</td>\n",
       "      <td>0.958213</td>\n",
       "      <td>0.970326</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.978310</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.760163</td>\n",
       "      <td>0.670632</td>\n",
       "      <td>0.704841</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.951551</td>\n",
       "      <td>0.958213</td>\n",
       "      <td>0.953879</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>combined_balanced_ecco_eval_results</td>\n",
       "      <td>0.830028</td>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.960894</td>\n",
       "      <td>0.764444</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.828148</td>\n",
       "      <td>0.854878</td>\n",
       "      <td>0.826405</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.864625</td>\n",
       "      <td>0.830028</td>\n",
       "      <td>0.833297</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>combined_balanced_combined_eval_results</td>\n",
       "      <td>0.882479</td>\n",
       "      <td>0.857283</td>\n",
       "      <td>0.978795</td>\n",
       "      <td>0.914018</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.950131</td>\n",
       "      <td>0.712598</td>\n",
       "      <td>0.814398</td>\n",
       "      <td>508.0</td>\n",
       "      <td>0.903707</td>\n",
       "      <td>0.845697</td>\n",
       "      <td>0.864208</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.890877</td>\n",
       "      <td>0.882479</td>\n",
       "      <td>0.877973</td>\n",
       "      <td>1404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>combined_balanced_caa_balanced_eval_results</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.750185</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.838877</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       DictName  accuracy  0_precision  \\\n",
       "0                              eval_results_caa  0.975504     0.987915   \n",
       "1                         caa_ecco_eval_results  0.745042     0.591346   \n",
       "2                     caa_combined_eval_results  0.865385     0.828837   \n",
       "3                 caa_caa_balanced_eval_results  0.971429     0.960000   \n",
       "4                             ecco_eval_results  0.957507     0.974790   \n",
       "5                         ecco_caa_eval_results  0.655620     0.990741   \n",
       "6                    ecco_combined_eval_results  0.825499     0.990950   \n",
       "7                ecco_caa_balanced_eval_results  0.609524     0.918919   \n",
       "8                         combined_eval_results  0.972934     0.985294   \n",
       "9                     combined_caa_eval_results  0.991354     0.995475   \n",
       "10                   combined_ecco_eval_results  0.991501     0.984496   \n",
       "11           combined_caa_balanced_eval_results  0.961905     0.947368   \n",
       "12                    caa_balanced_eval_results  0.866667     0.939394   \n",
       "13                balanced_caa_caa_eval_results  0.925072     0.998369   \n",
       "14               balanced_caa_ecco_eval_results  0.883853     0.822222   \n",
       "15           balanced_caa_combined_eval_results  0.913105     0.957447   \n",
       "16               combined_balanced_eval_results  0.833333     0.916667   \n",
       "17           combined_balanced_caa_eval_results  0.958213     0.970326   \n",
       "18          combined_balanced_ecco_eval_results  0.830028     0.695402   \n",
       "19      combined_balanced_combined_eval_results  0.882479     0.857283   \n",
       "20  combined_balanced_caa_balanced_eval_results  0.833333     0.916667   \n",
       "\n",
       "    0_recall  0_f1-score  0_support  1_precision  1_recall  1_f1-score  \\\n",
       "0   0.986425    0.987170      663.0     0.718750  0.741935    0.730159   \n",
       "1   0.960938    0.732143      128.0     0.965517  0.622222    0.756757   \n",
       "2   0.994420    0.904110      896.0     0.984802  0.637795    0.774194   \n",
       "3   1.000000    0.979592       72.0     1.000000  0.909091    0.952381   \n",
       "4   0.906250    0.939271      128.0     0.948718  0.986667    0.967320   \n",
       "5   0.645551    0.781735      663.0     0.103053  0.870968    0.184300   \n",
       "6   0.733259    0.842848      896.0     0.677463  0.988189    0.803843   \n",
       "7   0.472222    0.623853       72.0     0.441176  0.909091    0.594059   \n",
       "8   0.972098    0.978652      896.0     0.951923  0.974409    0.963035   \n",
       "9   0.995475    0.995475      663.0     0.903226  0.903226    0.903226   \n",
       "10  0.992188    0.988327      128.0     0.995536  0.991111    0.993318   \n",
       "11  1.000000    0.972973       72.0     1.000000  0.878788    0.935484   \n",
       "12  0.861111    0.898551       72.0     0.743590  0.878788    0.805556   \n",
       "13  0.923077    0.959248      663.0     0.370370  0.967742    0.535714   \n",
       "14  0.867188    0.844106      128.0     0.922018  0.893333    0.907449   \n",
       "15  0.904018    0.929966      896.0     0.845878  0.929134    0.885553   \n",
       "16  0.873016    0.894309       63.0     0.555556  0.666667    0.606061   \n",
       "17  0.986425    0.978310      663.0     0.550000  0.354839    0.431373   \n",
       "18  0.945312    0.801325      128.0     0.960894  0.764444    0.851485   \n",
       "19  0.978795    0.914018      896.0     0.950131  0.712598    0.814398   \n",
       "20  0.873016    0.894309       63.0     0.555556  0.666667    0.606061   \n",
       "\n",
       "    1_support  macro avg_precision  macro avg_recall  macro avg_f1-score  \\\n",
       "0        31.0             0.853333          0.864180            0.858664   \n",
       "1       225.0             0.778432          0.791580            0.744450   \n",
       "2       508.0             0.906820          0.816107            0.839152   \n",
       "3        33.0             0.980000          0.954545            0.965986   \n",
       "4       225.0             0.961754          0.946458            0.953296   \n",
       "5        31.0             0.546897          0.758259            0.483018   \n",
       "6       508.0             0.834207          0.860724            0.823346   \n",
       "7        33.0             0.680048          0.690657            0.608956   \n",
       "8       508.0             0.968609          0.973254            0.970843   \n",
       "9        31.0             0.949350          0.949350            0.949350   \n",
       "10      225.0             0.990016          0.991649            0.990823   \n",
       "11       33.0             0.973684          0.939394            0.954228   \n",
       "12       33.0             0.841492          0.869949            0.852053   \n",
       "13       31.0             0.684370          0.945409            0.747481   \n",
       "14      225.0             0.872120          0.880260            0.875778   \n",
       "15      508.0             0.901662          0.916576            0.907760   \n",
       "16       15.0             0.736111          0.769841            0.750185   \n",
       "17       31.0             0.760163          0.670632            0.704841   \n",
       "18      225.0             0.828148          0.854878            0.826405   \n",
       "19      508.0             0.903707          0.845697            0.864208   \n",
       "20       15.0             0.736111          0.769841            0.750185   \n",
       "\n",
       "    macro avg_support  weighted avg_precision  weighted avg_recall  \\\n",
       "0               694.0                0.975892             0.975504   \n",
       "1               353.0                0.829840             0.745042   \n",
       "2              1404.0                0.885269             0.865385   \n",
       "3               105.0                0.972571             0.971429   \n",
       "4               353.0                0.958172             0.957507   \n",
       "5               694.0                0.951089             0.655620   \n",
       "6              1404.0                0.877523             0.825499   \n",
       "7               105.0                0.768771             0.609524   \n",
       "8              1404.0                0.973220             0.972934   \n",
       "9               694.0                0.991354             0.991354   \n",
       "10              353.0                0.991533             0.991501   \n",
       "11              105.0                0.963910             0.961905   \n",
       "12              105.0                0.877855             0.866667   \n",
       "13              694.0                0.970317             0.925072   \n",
       "14              353.0                0.885832             0.883853   \n",
       "15             1404.0                0.917079             0.913105   \n",
       "16               78.0                0.847222             0.833333   \n",
       "17              694.0                0.951551             0.958213   \n",
       "18              353.0                0.864625             0.830028   \n",
       "19             1404.0                0.890877             0.882479   \n",
       "20               78.0                0.847222             0.833333   \n",
       "\n",
       "    weighted avg_f1-score  weighted avg_support  \n",
       "0                0.975689                 694.0  \n",
       "1                0.747832                 353.0  \n",
       "2                0.857103                1404.0  \n",
       "3                0.971040                 105.0  \n",
       "4                0.957150                 353.0  \n",
       "5                0.755049                 694.0  \n",
       "6                0.828735                1404.0  \n",
       "7                0.614489                 105.0  \n",
       "8                0.973001                1404.0  \n",
       "9                0.991354                 694.0  \n",
       "10               0.991508                 353.0  \n",
       "11               0.961191                 105.0  \n",
       "12               0.869324                 105.0  \n",
       "13               0.940329                 694.0  \n",
       "14               0.884481                 353.0  \n",
       "15               0.913896                1404.0  \n",
       "16               0.838877                  78.0  \n",
       "17               0.953879                 694.0  \n",
       "18               0.833297                 353.0  \n",
       "19               0.877973                1404.0  \n",
       "20               0.838877                  78.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_eval_results_dictionaries():\n",
    "    return {name: value for name, value in globals().items() if isinstance(value, dict) and 'eval_results' in name}\n",
    "\n",
    "eval_result_dictionaries = list_eval_results_dictionaries()\n",
    "\n",
    "dict_list = [{'DictName': name, ** eval_result_dictionaries[name]} for name in eval_result_dictionaries]\n",
    "\n",
    "dict_df = pd.DataFrame(dict_list)\n",
    "\n",
    "#dict_df = dict_df[['DictName'] + sorted(dict_df.columns.drop('DictName'),tolist())]\n",
    "\n",
    "\n",
    "def expand_dict_columns(df):\n",
    "    dict_columns = [col for col in df.columns if isinstance(df[col][0], dict)]\n",
    "    expanded_cols = []\n",
    "    for col in dict_columns:\n",
    "        expanded = pd.json_normalize(df[col])\n",
    "        expanded.columns = [f\"{col}_{key}\" for key in expanded.columns]\n",
    "        expanded_cols.append(expanded)\n",
    "    df = df.drop(columns=dict_columns)\n",
    "    if expanded_cols:\n",
    "        expanded_cols_df = pd.concat(expanded_cols, axis=1)\n",
    "        df = pd.concat([df, expanded_cols_df], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "dff = expand_dict_columns(dict_df)\n",
    "\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a99b756f-1ca8-4928-a373-b7971aa8b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv('../results/bert-translation-task.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
