{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c15355-92cc-472c-bb28-0c59f5fa452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset, load_dataset, ClassLabel, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df72b91e-0bc6-40bd-a1b3-2b4b7c60a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecco_train_df = pd.read_csv('../data/multilingual-task-data/ecco_train_no_dupl.csv')\n",
    "ecco_test_df = pd.read_csv('../data/multilingual-task-data/ecco_test_no_dupl.csv')\n",
    "\n",
    "ecco_train_df.rename(columns={\"monolingual\": \"label\",\"ecco_full_title\": \"text\"}, inplace=True)\n",
    "ecco_test_df.rename(columns={\"monolingual\": \"label\",\"ecco_full_title\": \"text\"}, inplace=True)\n",
    "\n",
    "ecco_train_dataset = Dataset.from_pandas(ecco_train_df)\n",
    "ecco_test_dataset = Dataset.from_pandas(ecco_test_df)\n",
    "\n",
    "ecco = DatasetDict({\"train\": ecco_train_dataset,\n",
    "                       \"test\": ecco_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cd8a72-6eab-4729-b137-1f4044427714",
   "metadata": {},
   "outputs": [],
   "source": [
    "caa_train_df = pd.read_csv('../data/multilingual-task-data/caa_train_df.csv')\n",
    "caa_test_df = pd.read_csv('../data/multilingual-task-data/caa_test_df.csv')\n",
    "\n",
    "caa_train_df.rename(columns={\"monolingual\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "caa_test_df.rename(columns={\"monolingual\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "caa_train_dataset = Dataset.from_pandas(caa_train_df)\n",
    "caa_test_dataset = Dataset.from_pandas(caa_test_df)\n",
    "\n",
    "caa = DatasetDict({\"train\": caa_train_dataset,\n",
    "                       \"test\": caa_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5299ed-65ac-4f18-af49-34628bcf9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_caa_train_df = pd.read_csv('../data/multilingual-task-data/balanced_caa_train_df.csv')\n",
    "balanced_caa_test_df = pd.read_csv('../data/multilingual-task-data/balanced_caa_test_df.csv')\n",
    "\n",
    "balanced_caa_train_df.rename(columns={\"monolingual\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "balanced_caa_test_df.rename(columns={\"monolingual\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "balanced_caa_train_dataset = Dataset.from_pandas(balanced_caa_train_df)\n",
    "balanced_caa_test_dataset = Dataset.from_pandas(balanced_caa_test_df)\n",
    "\n",
    "balanced_caa = DatasetDict({\"train\": balanced_caa_train_dataset,\n",
    "                       \"test\": balanced_caa_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df72979-2a52-4e03-b402-6bf3dcbc21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_df = pd.read_csv('../data/multilingual-task-data/combined_train_no_dupl.csv')\n",
    "combined_test_df = pd.read_csv('../data/multilingual-task-data/combined_test_no_dupl.csv')\n",
    "\n",
    "combined_train_df.rename(columns={\"monolingual\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "combined_test_df.rename(columns={\"monolingual\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "combined_train_dataset = Dataset.from_pandas(combined_train_df)\n",
    "combined_test_dataset = Dataset.from_pandas(combined_test_df)\n",
    "\n",
    "combined = DatasetDict({\"train\": combined_train_dataset,\n",
    "                       \"test\": combined_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395d97e7-7764-475c-90bb-d032aae7441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_balanced_caa_train_df = pd.read_csv('../data/multilingual-task-data/balanced_data_both_language_train_df.csv')\n",
    "combined_balanced_caa_test_df = pd.read_csv('../data/multilingual-task-data/balanced_data_both_language_test_df.csv')\n",
    "\n",
    "combined_balanced_caa_train_df.rename(columns={\"monolingual\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "combined_balanced_caa_test_df.rename(columns={\"monolingual\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "combined_balanced_caa_train_dataset = Dataset.from_pandas(combined_balanced_caa_train_df)\n",
    "combined_balanced_caa_test_dataset = Dataset.from_pandas(combined_balanced_caa_test_df)\n",
    "\n",
    "combined_balanced_caa = DatasetDict({\"train\": combined_balanced_caa_train_dataset,\n",
    "                       \"test\": combined_balanced_caa_test_dataset,})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b7e701-d22b-4f44-a18e-a5e7a223ca2a",
   "metadata": {},
   "source": [
    "# Trained on CAA - Standard BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "097ab9b8-3592-4168-af9c-3a8f6c8cb445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630d24b6-63b5-475e-9576-c8df03709e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620a3838-f8dc-4081-86f3-e91cddfd6398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c22d10fc2a4385b455d8a199989643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2928 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3759b26e7d427287d1b23c2b5a0223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_caa = caa.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01f8e2b3-e9e7-47b0-877e-d6201e3854f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f4110e4-8c0d-4340-a90c-56534ca261e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc35000a-6c3a-4208-916f-da8de46403b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85fe3f3f-66bb-446d-9983-130c8c6333b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-multilingual-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ded19bb3-fcf6-4002-a75b-ba5c9c2873d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5de3d06-6260-4dcf-b3f2-92dfa7aaae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='915' max='915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [915/915 03:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140605</td>\n",
       "      <td>0.967213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.114863</td>\n",
       "      <td>0.969945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.120606</td>\n",
       "      <td>0.965847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.146879</td>\n",
       "      <td>0.961749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.134911</td>\n",
       "      <td>0.964481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "     output_dir = \"./results_mono\",\n",
    "     learning_rate=2e-5,\n",
    "     per_device_train_batch_size=8,\n",
    "     per_device_eval_batch_size=8,\n",
    "     num_train_epochs=5,\n",
    "     weight_decay=0.01,\n",
    "     evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "     model=model,\n",
    "     args=training_args,\n",
    "     train_dataset=tokenized_caa[\"train\"],\n",
    "     eval_dataset=tokenized_caa[\"test\"],\n",
    "     tokenizer=tokenizer,\n",
    "     data_collator=data_collator,\n",
    "     compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bert_models_monolingual/caa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e11de723-5434-4670-86ab-c5821b97cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AutoModelForSequenceClassification.from_pretrained('bert_models_monolingual/caa/', local_files_only=True)\n",
    "\n",
    "#model = model.to('cuda')\n",
    "\n",
    "#trainer = Trainer(model=model)\n",
    "\n",
    "#trainer.model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eac04df0-a407-4381-a047-bf37379d5f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538856ca25e142e8b3a0928f9af42043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=max_length)\n",
    "\n",
    "new_text_list = caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = caa_test_df[\"label\"]\n",
    "\n",
    "eval_results_caa = classification_report(true_labels, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64e84afc-f87e-4bac-9a55-26ab81657cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.5882352941176471,\n",
       "  'recall': 0.625,\n",
       "  'f1-score': 0.6060606060606061,\n",
       "  'support': 32.0},\n",
       " '1': {'precision': 0.9828080229226361,\n",
       "  'recall': 0.98,\n",
       "  'f1-score': 0.9814020028612304,\n",
       "  'support': 700.0},\n",
       " 'accuracy': 0.9644808743169399,\n",
       " 'macro avg': {'precision': 0.7855216585201417,\n",
       "  'recall': 0.8025,\n",
       "  'f1-score': 0.7937313044609182,\n",
       "  'support': 732.0},\n",
       " 'weighted avg': {'precision': 0.965558941881981,\n",
       "  'recall': 0.9644808743169399,\n",
       "  'f1-score': 0.964993635787979,\n",
       "  'support': 732.0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results_caa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c945d9-61be-47b3-ad38-4df16c337587",
   "metadata": {},
   "source": [
    "# tested on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ee32ed7-9307-49d8-a700-df5a81584e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e7a47f18064c5797409fd428d4816c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = ecco_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = ecco_test_df[\"label\"]\n",
    "\n",
    "caa_ecco_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14d4cd38-baeb-4266-8558-f5a2d61e7094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.47619047619047616,\n",
       "  'recall': 0.18867924528301888,\n",
       "  'f1-score': 0.2702702702702703,\n",
       "  'support': 106.0},\n",
       " '1': {'precision': 0.7957244655581948,\n",
       "  'recall': 0.938375350140056,\n",
       "  'f1-score': 0.8611825192802056,\n",
       "  'support': 357.0},\n",
       " 'accuracy': 0.7667386609071274,\n",
       " 'macro avg': {'precision': 0.6359574708743354,\n",
       "  'recall': 0.5635272977115374,\n",
       "  'f1-score': 0.565726394775238,\n",
       "  'support': 463.0},\n",
       " 'weighted avg': {'precision': 0.7225698157245487,\n",
       "  'recall': 0.7667386609071274,\n",
       "  'f1-score': 0.7258980735025531,\n",
       "  'support': 463.0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caa_ecco_eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32fcf2-f00b-43d5-aac2-bf00679360b8",
   "metadata": {},
   "source": [
    "# Tested on combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09593c22-0739-4620-a1ba-8fb7b613c848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae817d2e054848acb595d75872206b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_test_df[\"label\"]\n",
    "\n",
    "caa_combined_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f57579a2-a462-4767-929b-4fa8476e5344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.691358024691358,\n",
       "  'recall': 0.35,\n",
       "  'f1-score': 0.46473029045643155,\n",
       "  'support': 160.0},\n",
       " '1': {'precision': 0.9066427289048474,\n",
       "  'recall': 0.9758454106280193,\n",
       "  'f1-score': 0.9399720800372267,\n",
       "  'support': 1035.0},\n",
       " 'accuracy': 0.8920502092050209,\n",
       " 'macro avg': {'precision': 0.7990003767981027,\n",
       "  'recall': 0.6629227053140097,\n",
       "  'f1-score': 0.7023511852468292,\n",
       "  'support': 1195.0},\n",
       " 'weighted avg': {'precision': 0.8778179986335852,\n",
       "  'recall': 0.8920502092050209,\n",
       "  'f1-score': 0.8763413801770366,\n",
       "  'support': 1195.0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caa_combined_eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b4336-fc35-4bb9-b21c-19fbe084816e",
   "metadata": {},
   "source": [
    "# tested on caa balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87486d3b-5464-4ba5-bfb8-cae4e50010ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85945da4388b4a69a4be758a046f254f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = balanced_caa_test_df[\"label\"]\n",
    "\n",
    "caa_caa_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8886f83c-f489-4644-86f7-18db4f85c2b1",
   "metadata": {},
   "source": [
    "# Trained on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c776a8c-a6a0-4340-b45c-cc7acb94ced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-multilingual-cased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e40a9464-4d55-435c-b255-73ac375cd30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d430c8489e9b49449563a17ac72da24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1852 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d88a136aff64b2b8f0cf475d618dfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ecco = ecco.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ca32e14-c1d7-4e8f-96e1-5080d23a4c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='580' max='580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [580/580 02:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.283713</td>\n",
       "      <td>0.917927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268061</td>\n",
       "      <td>0.930886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.287628</td>\n",
       "      <td>0.930886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.322700</td>\n",
       "      <td>0.928726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.207300</td>\n",
       "      <td>0.323040</td>\n",
       "      <td>0.928726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ecco[\"train\"],\n",
    "    eval_dataset=tokenized_ecco[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bert_models_monolingual/ecco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58af7c6b-d47e-407f-94e5-a67d34a7731d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc5e108e08d4cbe80c199f05263f0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = ecco_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = ecco_test_df[\"label\"]\n",
    "\n",
    "ecco_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739121ee-223f-4733-a6b3-0b1e34cdf969",
   "metadata": {},
   "source": [
    "# Tested on CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "903f0206-8d3e-44a5-bd18-981bf313a471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd87e806dcae4423ad1fe67e51f881b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = caa_test_df[\"label\"]\n",
    "\n",
    "ecco_caa_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778575f7-c3d3-491e-a836-6dfe83326e76",
   "metadata": {},
   "source": [
    "# Tested on combined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac8d62d7-54fe-4962-ab18-d62ecec29dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4192b7ce53c8467bb5f6a8d60c1be8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_test_df[\"label\"]\n",
    "\n",
    "ecco_combined_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b24b4e-f52e-4454-b44d-2465d1124bab",
   "metadata": {},
   "source": [
    "# Tested on balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f2cc496-4692-417e-80c0-90220ed20508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cab7118c39841de834e1b884050bf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = balanced_caa_test_df[\"label\"]\n",
    "\n",
    "ecco_caa_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2198b054-35d5-46fc-8ddc-86519b78cbd0",
   "metadata": {},
   "source": [
    "# Trained on both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10f8f8ca-13ac-42ab-b857-f3ddb9361f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-multilingual-cased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a049bca-76c8-4fe8-8e6a-d779840db5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff71dcbd5a74ed6aa5841fc3b851c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4778 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3920f32f4da74afe951f6a5dc8a16cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_combined = combined.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf8b4bdc-d1ac-460b-8ae3-b399103c9443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1495' max='1495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1495/1495 06:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.196145</td>\n",
       "      <td>0.937238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.194198</td>\n",
       "      <td>0.945607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.198522</td>\n",
       "      <td>0.949791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.211805</td>\n",
       "      <td>0.944770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.243415</td>\n",
       "      <td>0.943096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_combined[\"train\"],\n",
    "    eval_dataset=tokenized_combined[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bert_models_monolingual/combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af900a60-f643-491b-a920-6684ef001e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba70697e184f4782aa0086eb8dd042a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_test_df[\"label\"]\n",
    "\n",
    "combined_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95745824-214a-4896-9961-6c666ce7658e",
   "metadata": {},
   "source": [
    "# Tested on CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "977e2a41-14cc-49d9-a6e3-9a55a844acaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1713159cc39e44a598a0e7170d81a4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = caa_test_df[\"label\"]\n",
    "\n",
    "combined_caa_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e7c1a-94b5-4330-82ab-2f4a038406cb",
   "metadata": {},
   "source": [
    "# Tested on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbd0fb6e-9f6c-492c-b7ee-4156a91296fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d56cc9fc5641c7a5129446b9464609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = ecco_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = ecco_test_df[\"label\"]\n",
    "\n",
    "combined_ecco_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec6327-8e15-4038-b22b-5c8380e22886",
   "metadata": {},
   "source": [
    "# Tested on CAA balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ad703ce-ab2d-42fe-afa5-defd0c9265e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6805ec96cb8c420aaf0151f150cc082e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = balanced_caa_test_df[\"label\"]\n",
    "\n",
    "combined_caa_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4f258-00ec-4149-be64-f36dee5d4ea6",
   "metadata": {},
   "source": [
    "# Trained on CAA Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb685d50-7f1d-4d00-b389-5d37a09d37cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-multilingual-cased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5f675cd-a9b5-4f20-8d34-77253e386c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09678622dab431896a6640a9906af56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a01d6aff1634c998dde484c676e70b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_balanced_caa = balanced_caa.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d4f47a2-d84f-455a-bea3-3993090fa3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:16, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695817</td>\n",
       "      <td>0.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.574828</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.540289</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.590447</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.625232</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.824046</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.728272</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.745822</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_balanced_caa[\"train\"],\n",
    "    eval_dataset=tokenized_balanced_caa[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bert_models_monolingual/balanced_caa/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c24496d-b20e-4f08-bb28-6047cfc3d60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432066c29954491f96c3bae077e9230f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = balanced_caa_test_df[\"label\"]\n",
    "\n",
    "caa_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7385a57-1707-4869-9201-43306e49d6c9",
   "metadata": {},
   "source": [
    "# Tested on CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6db0212e-b533-4ab0-91d6-33c153d6d5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8ed125fb1345d8bce16c93107c68a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = caa_test_df[\"label\"]\n",
    "\n",
    "balanced_caa_caa_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d707d23-e4d4-4a5a-b48e-55c87b1aa8f8",
   "metadata": {},
   "source": [
    "# Tested on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70954744-3d8a-467a-b2d8-45e24d5e8fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e79085dc654de890fff16e95262edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = ecco_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = ecco_test_df[\"label\"]\n",
    "\n",
    "balanced_caa_ecco_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e10e433-3253-4eb8-b688-6cafe17a7bf7",
   "metadata": {},
   "source": [
    "# Tested on combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9f35ef6-7f41-418b-9615-9f4447ebb69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fdd2082240478e8c5a41be0f1e893c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_test_df[\"label\"]\n",
    "\n",
    "balanced_caa_combined_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aad13f-e4ad-4844-9b1c-6b8132357d32",
   "metadata": {},
   "source": [
    "# Trained on combined_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52002238-8550-4f72-ba40-84d66f59ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"google-bert/bert-base-multilingual-cased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8fd4d962-1b71-4117-b4d2-8ed4c16ed64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beba2a18a3974016b3d2184480c4f545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6eeba742684d56a723cf1176c3090e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_combined_balanced_caa = combined_balanced_caa.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da269a1c-52da-4a95-afb9-17828b3ab1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 00:32, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.686123</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.727558</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.672520</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.678008</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.714965</td>\n",
       "      <td>0.602564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.609603</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.677560</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.673988</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_combined_balanced_caa[\"train\"],\n",
    "    eval_dataset=tokenized_combined_balanced_caa[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"bert_models_monolingual/balanced_combined/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74b4d89f-3dd2-4c26-9366-b70f2a1c54e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab5d54e845a4a7298c874038e42e9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_balanced_caa_test_df[\"label\"]\n",
    "\n",
    "combined_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096efe6b-52fa-44bc-bd7a-ceb868641c77",
   "metadata": {},
   "source": [
    "# Tested on CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e211fd9-7b80-4299-9876-c0832b318b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6744746ecd415a8d627e9dba06b869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = caa_test_df[\"label\"]\n",
    "\n",
    "combined_balanced_caa_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26834d88-55b1-4398-99bd-e7d98d0f24ed",
   "metadata": {},
   "source": [
    "# Tested on ECCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28844ce6-4548-4492-a382-a0cfe00c9530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f08bba354744563b1ba6a25c8441d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = ecco_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = ecco_test_df[\"label\"]\n",
    "\n",
    "combined_balanced_ecco_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136cadf8-b74e-4e02-80c7-93591653efb4",
   "metadata": {},
   "source": [
    "# Tested on combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c02581d-55bb-4e0c-aaa6-9a4820bfead9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778d58c95b984905a10c95dd75f412c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_test_df[\"label\"]\n",
    "\n",
    "combined_balanced_combined_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f08d653-efdc-461c-96eb-f493e1c26f5b",
   "metadata": {},
   "source": [
    "# Tested on CAA balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5977edb5-32b9-44bb-9583-453165c8bfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689c2cbbeaa74add805eb2f3e3732b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/78 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_text_list = combined_balanced_caa_test_df[\"text\"].tolist()\n",
    "\n",
    "new_dataset = Dataset.from_dict({\"text\": new_text_list})\n",
    "\n",
    "tokenized_new_dataset = new_dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "predictions = trainer.predict(tokenized_new_dataset)\n",
    "\n",
    "logits = predictions.predictions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predicted_labels = np.argmax(logits, axis=1).tolist()\n",
    "\n",
    "true_labels = combined_balanced_caa_test_df[\"label\"]\n",
    "\n",
    "combined_balanced_caa_balanced_eval_results = classification_report(true_labels, predicted_labels, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2ddd4b5-5061-4de0-bc2d-850ca4bb631f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DictName</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>0_precision</th>\n",
       "      <th>0_recall</th>\n",
       "      <th>0_f1-score</th>\n",
       "      <th>0_support</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_recall</th>\n",
       "      <th>1_f1-score</th>\n",
       "      <th>1_support</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>macro avg_support</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <th>weighted avg_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eval_results_caa</td>\n",
       "      <td>0.964481</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.982808</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.785522</td>\n",
       "      <td>0.802500</td>\n",
       "      <td>0.793731</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.965559</td>\n",
       "      <td>0.964481</td>\n",
       "      <td>0.964994</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caa_ecco_eval_results</td>\n",
       "      <td>0.766739</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.795724</td>\n",
       "      <td>0.938375</td>\n",
       "      <td>0.861183</td>\n",
       "      <td>357.0</td>\n",
       "      <td>0.635957</td>\n",
       "      <td>0.563527</td>\n",
       "      <td>0.565726</td>\n",
       "      <td>463.0</td>\n",
       "      <td>0.722570</td>\n",
       "      <td>0.766739</td>\n",
       "      <td>0.725898</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>caa_combined_eval_results</td>\n",
       "      <td>0.892050</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.464730</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.906643</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>0.939972</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.799000</td>\n",
       "      <td>0.662923</td>\n",
       "      <td>0.702351</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>0.877818</td>\n",
       "      <td>0.892050</td>\n",
       "      <td>0.876341</td>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caa_caa_balanced_eval_results</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ecco_eval_results</td>\n",
       "      <td>0.928726</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.940217</td>\n",
       "      <td>0.969188</td>\n",
       "      <td>0.954483</td>\n",
       "      <td>357.0</td>\n",
       "      <td>0.912214</td>\n",
       "      <td>0.880820</td>\n",
       "      <td>0.895152</td>\n",
       "      <td>463.0</td>\n",
       "      <td>0.927395</td>\n",
       "      <td>0.928726</td>\n",
       "      <td>0.927316</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ecco_caa_eval_results</td>\n",
       "      <td>0.748634</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>0.851613</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.540972</td>\n",
       "      <td>0.689643</td>\n",
       "      <td>0.515092</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.939587</td>\n",
       "      <td>0.748634</td>\n",
       "      <td>0.822190</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ecco_combined_eval_results</td>\n",
       "      <td>0.823431</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.550107</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.965011</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.890161</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.691244</td>\n",
       "      <td>0.816168</td>\n",
       "      <td>0.720134</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>0.891701</td>\n",
       "      <td>0.823431</td>\n",
       "      <td>0.844631</td>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ecco_caa_balanced_eval_results</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.564583</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>combined_eval_results</td>\n",
       "      <td>0.943096</td>\n",
       "      <td>0.815068</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.960915</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.967370</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.887992</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>0.872574</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>0.941388</td>\n",
       "      <td>0.943096</td>\n",
       "      <td>0.941986</td>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>combined_caa_eval_results</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.990028</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.991441</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.911681</td>\n",
       "      <td>0.887054</td>\n",
       "      <td>0.898946</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.983178</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.983354</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>combined_ecco_eval_results</td>\n",
       "      <td>0.961123</td>\n",
       "      <td>0.931373</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.969529</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.974930</td>\n",
       "      <td>357.0</td>\n",
       "      <td>0.950451</td>\n",
       "      <td>0.938309</td>\n",
       "      <td>0.944196</td>\n",
       "      <td>463.0</td>\n",
       "      <td>0.960793</td>\n",
       "      <td>0.961123</td>\n",
       "      <td>0.960858</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>combined_caa_balanced_eval_results</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.925824</td>\n",
       "      <td>0.918864</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.927333</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.925558</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>caa_balanced_eval_results</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>balanced_caa_caa_eval_results</td>\n",
       "      <td>0.531421</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.989041</td>\n",
       "      <td>0.515714</td>\n",
       "      <td>0.677934</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.532668</td>\n",
       "      <td>0.695357</td>\n",
       "      <td>0.409143</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.949140</td>\n",
       "      <td>0.531421</td>\n",
       "      <td>0.654433</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>balanced_caa_ecco_eval_results</td>\n",
       "      <td>0.624190</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.806020</td>\n",
       "      <td>0.675070</td>\n",
       "      <td>0.734756</td>\n",
       "      <td>357.0</td>\n",
       "      <td>0.549351</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.545156</td>\n",
       "      <td>463.0</td>\n",
       "      <td>0.688496</td>\n",
       "      <td>0.624190</td>\n",
       "      <td>0.647941</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balanced_caa_combined_eval_results</td>\n",
       "      <td>0.580753</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.259970</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.585507</td>\n",
       "      <td>0.707531</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.532009</td>\n",
       "      <td>0.567754</td>\n",
       "      <td>0.483751</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>0.796923</td>\n",
       "      <td>0.580753</td>\n",
       "      <td>0.647606</td>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>combined_balanced_eval_results</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.614370</td>\n",
       "      <td>0.614370</td>\n",
       "      <td>0.614370</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>combined_balanced_caa_eval_results</td>\n",
       "      <td>0.534153</td>\n",
       "      <td>0.072022</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.132316</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.983827</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.681606</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.527925</td>\n",
       "      <td>0.666964</td>\n",
       "      <td>0.406961</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.943967</td>\n",
       "      <td>0.534153</td>\n",
       "      <td>0.657593</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>combined_balanced_ecco_eval_results</td>\n",
       "      <td>0.643629</td>\n",
       "      <td>0.377593</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.524496</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.579832</td>\n",
       "      <td>0.715026</td>\n",
       "      <td>357.0</td>\n",
       "      <td>0.655013</td>\n",
       "      <td>0.719161</td>\n",
       "      <td>0.619761</td>\n",
       "      <td>463.0</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.643629</td>\n",
       "      <td>0.671406</td>\n",
       "      <td>463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>combined_balanced_combined_eval_results</td>\n",
       "      <td>0.604184</td>\n",
       "      <td>0.233390</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.366801</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.962171</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.712112</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.597781</td>\n",
       "      <td>0.710734</td>\n",
       "      <td>0.539456</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>0.864594</td>\n",
       "      <td>0.604184</td>\n",
       "      <td>0.665878</td>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>combined_balanced_caa_balanced_eval_results</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.614370</td>\n",
       "      <td>0.614370</td>\n",
       "      <td>0.614370</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       DictName  accuracy  0_precision  \\\n",
       "0                              eval_results_caa  0.964481     0.588235   \n",
       "1                         caa_ecco_eval_results  0.766739     0.476190   \n",
       "2                     caa_combined_eval_results  0.892050     0.691358   \n",
       "3                 caa_caa_balanced_eval_results  0.850000     0.900000   \n",
       "4                             ecco_eval_results  0.928726     0.884211   \n",
       "5                         ecco_caa_eval_results  0.748634     0.104167   \n",
       "6                    ecco_combined_eval_results  0.823431     0.417476   \n",
       "7                ecco_caa_balanced_eval_results  0.550000     0.375000   \n",
       "8                         combined_eval_results  0.943096     0.815068   \n",
       "9                     combined_caa_eval_results  0.983607     0.833333   \n",
       "10                   combined_ecco_eval_results  0.961123     0.931373   \n",
       "11           combined_caa_balanced_eval_results  0.925000     0.866667   \n",
       "12                    caa_balanced_eval_results  0.750000     0.642857   \n",
       "13                balanced_caa_caa_eval_results  0.531421     0.076294   \n",
       "14               balanced_caa_ecco_eval_results  0.624190     0.292683   \n",
       "15           balanced_caa_combined_eval_results  0.580753     0.170213   \n",
       "16               combined_balanced_eval_results  0.615385     0.634146   \n",
       "17           combined_balanced_caa_eval_results  0.534153     0.072022   \n",
       "18          combined_balanced_ecco_eval_results  0.643629     0.377593   \n",
       "19      combined_balanced_combined_eval_results  0.604184     0.233390   \n",
       "20  combined_balanced_caa_balanced_eval_results  0.615385     0.634146   \n",
       "\n",
       "    0_recall  0_f1-score  0_support  1_precision  1_recall  1_f1-score  \\\n",
       "0   0.625000    0.606061       32.0     0.982808  0.980000    0.981402   \n",
       "1   0.188679    0.270270      106.0     0.795724  0.938375    0.861183   \n",
       "2   0.350000    0.464730      160.0     0.906643  0.975845    0.939972   \n",
       "3   0.642857    0.750000       14.0     0.833333  0.961538    0.892857   \n",
       "4   0.792453    0.835821      106.0     0.940217  0.969188    0.954483   \n",
       "5   0.625000    0.178571       32.0     0.977778  0.754286    0.851613   \n",
       "6   0.806250    0.550107      160.0     0.965011  0.826087    0.890161   \n",
       "7   0.428571    0.400000       14.0     0.666667  0.615385    0.640000   \n",
       "8   0.743750    0.777778      160.0     0.960915  0.973913    0.967370   \n",
       "9   0.781250    0.806452       32.0     0.990028  0.992857    0.991441   \n",
       "10  0.896226    0.913462      106.0     0.969529  0.980392    0.974930   \n",
       "11  0.928571    0.896552       14.0     0.960000  0.923077    0.941176   \n",
       "12  0.642857    0.642857       14.0     0.807692  0.807692    0.807692   \n",
       "13  0.875000    0.140351       32.0     0.989041  0.515714    0.677934   \n",
       "14  0.452830    0.355556      106.0     0.806020  0.675070    0.734756   \n",
       "15  0.550000    0.259970      160.0     0.893805  0.585507    0.707531   \n",
       "16  0.634146    0.634146       41.0     0.594595  0.594595    0.594595   \n",
       "17  0.812500    0.132316       32.0     0.983827  0.521429    0.681606   \n",
       "18  0.858491    0.524496      106.0     0.932432  0.579832    0.715026   \n",
       "19  0.856250    0.366801      160.0     0.962171  0.565217    0.712112   \n",
       "20  0.634146    0.634146       41.0     0.594595  0.594595    0.594595   \n",
       "\n",
       "    1_support  macro avg_precision  macro avg_recall  macro avg_f1-score  \\\n",
       "0       700.0             0.785522          0.802500            0.793731   \n",
       "1       357.0             0.635957          0.563527            0.565726   \n",
       "2      1035.0             0.799000          0.662923            0.702351   \n",
       "3        26.0             0.866667          0.802198            0.821429   \n",
       "4       357.0             0.912214          0.880820            0.895152   \n",
       "5       700.0             0.540972          0.689643            0.515092   \n",
       "6      1035.0             0.691244          0.816168            0.720134   \n",
       "7        26.0             0.520833          0.521978            0.520000   \n",
       "8      1035.0             0.887992          0.858832            0.872574   \n",
       "9       700.0             0.911681          0.887054            0.898946   \n",
       "10      357.0             0.950451          0.938309            0.944196   \n",
       "11       26.0             0.913333          0.925824            0.918864   \n",
       "12       26.0             0.725275          0.725275            0.725275   \n",
       "13      700.0             0.532668          0.695357            0.409143   \n",
       "14      357.0             0.549351          0.563950            0.545156   \n",
       "15     1035.0             0.532009          0.567754            0.483751   \n",
       "16       37.0             0.614370          0.614370            0.614370   \n",
       "17      700.0             0.527925          0.666964            0.406961   \n",
       "18      357.0             0.655013          0.719161            0.619761   \n",
       "19     1035.0             0.597781          0.710734            0.539456   \n",
       "20       37.0             0.614370          0.614370            0.614370   \n",
       "\n",
       "    macro avg_support  weighted avg_precision  weighted avg_recall  \\\n",
       "0               732.0                0.965559             0.964481   \n",
       "1               463.0                0.722570             0.766739   \n",
       "2              1195.0                0.877818             0.892050   \n",
       "3                40.0                0.856667             0.850000   \n",
       "4               463.0                0.927395             0.928726   \n",
       "5               732.0                0.939587             0.748634   \n",
       "6              1195.0                0.891701             0.823431   \n",
       "7                40.0                0.564583             0.550000   \n",
       "8              1195.0                0.941388             0.943096   \n",
       "9               732.0                0.983178             0.983607   \n",
       "10              463.0                0.960793             0.961123   \n",
       "11               40.0                0.927333             0.925000   \n",
       "12               40.0                0.750000             0.750000   \n",
       "13              732.0                0.949140             0.531421   \n",
       "14              463.0                0.688496             0.624190   \n",
       "15             1195.0                0.796923             0.580753   \n",
       "16               78.0                0.615385             0.615385   \n",
       "17              732.0                0.943967             0.534153   \n",
       "18              463.0                0.805407             0.643629   \n",
       "19             1195.0                0.864594             0.604184   \n",
       "20               78.0                0.615385             0.615385   \n",
       "\n",
       "    weighted avg_f1-score  weighted avg_support  \n",
       "0                0.964994                 732.0  \n",
       "1                0.725898                 463.0  \n",
       "2                0.876341                1195.0  \n",
       "3                0.842857                  40.0  \n",
       "4                0.927316                 463.0  \n",
       "5                0.822190                 732.0  \n",
       "6                0.844631                1195.0  \n",
       "7                0.556000                  40.0  \n",
       "8                0.941986                1195.0  \n",
       "9                0.983354                 732.0  \n",
       "10               0.960858                 463.0  \n",
       "11               0.925558                  40.0  \n",
       "12               0.750000                  40.0  \n",
       "13               0.654433                 732.0  \n",
       "14               0.647941                 463.0  \n",
       "15               0.647606                1195.0  \n",
       "16               0.615385                  78.0  \n",
       "17               0.657593                 732.0  \n",
       "18               0.671406                 463.0  \n",
       "19               0.665878                1195.0  \n",
       "20               0.615385                  78.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_eval_results_dictionaries():\n",
    "    return {name: value for name, value in globals().items() if isinstance(value, dict) and 'eval_results' in name}\n",
    "\n",
    "eval_result_dictionaries = list_eval_results_dictionaries()\n",
    "\n",
    "dict_list = [{'DictName': name, ** eval_result_dictionaries[name]} for name in eval_result_dictionaries]\n",
    "\n",
    "dict_df = pd.DataFrame(dict_list)\n",
    "\n",
    "#dict_df = dict_df[['DictName'] + sorted(dict_df.columns.drop('DictName'),tolist())]\n",
    "\n",
    "\n",
    "def expand_dict_columns(df):\n",
    "    dict_columns = [col for col in df.columns if isinstance(df[col][0], dict)]\n",
    "    expanded_cols = []\n",
    "    for col in dict_columns:\n",
    "        expanded = pd.json_normalize(df[col])\n",
    "        expanded.columns = [f\"{col}_{key}\" for key in expanded.columns]\n",
    "        expanded_cols.append(expanded)\n",
    "    df = df.drop(columns=dict_columns)\n",
    "    if expanded_cols:\n",
    "        expanded_cols_df = pd.concat(expanded_cols, axis=1)\n",
    "        df = pd.concat([df, expanded_cols_df], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "dff = expand_dict_columns(dict_df)\n",
    "\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a99b756f-1ca8-4928-a373-b7971aa8b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv('../results/bert-multilingual-task', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
