{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c15355-92cc-472c-bb28-0c59f5fa452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset, load_dataset, ClassLabel, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73b2b50-daf4-47e4-aeaa-e531f8502d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecco_train_df = pd.read_csv('../data/translation-task-data/ecco_monolingual_train_no_dupl.csv')\n",
    "ecco_test_df = pd.read_csv('../data/translation-task-data/ecco_monolingual_test_no_dupl.csv')\n",
    "\n",
    "ecco_train_df.rename(columns={\"monolingual_translations\": \"label\", \"ecco_full_title\": \"text\"}, inplace=True)\n",
    "ecco_test_df.rename(columns={\"monolingual_translations\": \"label\", \"ecco_full_title\": \"text\"}, inplace=True)\n",
    "\n",
    "ecco_train_dataset = Dataset.from_pandas(ecco_train_df)\n",
    "ecco_test_dataset = Dataset.from_pandas(ecco_test_df)\n",
    "\n",
    "ecco = DatasetDict({\"train\": ecco_train_dataset,\n",
    "                       \"test\": ecco_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4cd8a72-6eab-4729-b137-1f4044427714",
   "metadata": {},
   "outputs": [],
   "source": [
    "caa_train_df = pd.read_csv('../data/translation-task-data/caa_monolingual_train.csv')\n",
    "caa_test_df = pd.read_csv('../data/translation-task-data/caa_monolingual_test.csv')\n",
    "\n",
    "caa_train_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "caa_test_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "caa_train_dataset = Dataset.from_pandas(caa_train_df)\n",
    "caa_test_dataset = Dataset.from_pandas(caa_test_df)\n",
    "\n",
    "caa = DatasetDict({\"train\": caa_train_dataset,\n",
    "                       \"test\": caa_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5299ed-65ac-4f18-af49-34628bcf9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_caa_train_df = pd.read_csv('../data/translation-task-data/balanced_data_both_language_train_df.csv')\n",
    "balanced_caa_test_df = pd.read_csv('../data/translation-task-data/balanced_data_both_language_test_df.csv')\n",
    "\n",
    "balanced_caa_train_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "balanced_caa_test_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "balanced_caa_train_dataset = Dataset.from_pandas(balanced_caa_train_df)\n",
    "balanced_caa_test_dataset = Dataset.from_pandas(balanced_caa_test_df)\n",
    "\n",
    "balanced_caa = DatasetDict({\"train\": balanced_caa_train_dataset,\n",
    "                       \"test\": balanced_caa_test_dataset,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df72979-2a52-4e03-b402-6bf3dcbc21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_df = pd.read_csv('../data/translation-task-data/combined_monolingual_train_no_dupl.csv')\n",
    "combined_test_df = pd.read_csv('../data/translation-task-data/combined_monolingual_test_no_dupl.csv')\n",
    "\n",
    "combined_train_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "combined_test_df.rename(columns={\"monolingual_translations\": \"label\", \"title\": \"text\"}, inplace=True)\n",
    "\n",
    "combined_train_dataset = Dataset.from_pandas(combined_train_df)\n",
    "combined_test_dataset = Dataset.from_pandas(combined_test_df)\n",
    "\n",
    "combined = DatasetDict({\"train\": combined_train_dataset,\n",
    "                       \"test\": combined_test_dataset,})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c7bfa-487b-4022-b846-5927c50d8539",
   "metadata": {},
   "source": [
    "# Trained on CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578ce36d-a057-4648-8a59-702d2dcccd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d32edf34-fc8d-4ad0-86eb-6a75f0b8004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitModel, SetFitTrainer, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37fa0d3-cdaf-4e28-aef0-aba07e63e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel\n",
    "from typing import Dict, Any\n",
    "\n",
    "def model_init(params: Dict[str, Any]) -> SetFitModel:\n",
    "    params = params or {}\n",
    "    max_iter = params.get(\"max_iter\", 100)\n",
    "    solver = params.get(\"solver\", \"liblinear\")\n",
    "    params = {\n",
    "        \"head_params\": {\n",
    "            \"max_iter\": max_iter,\n",
    "            \"solver\": solver,\n",
    "        }\n",
    "    }\n",
    "    return SetFitModel.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v2\", **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b2984e-5f86-45ee-973c-49763149d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna import Trial\n",
    "from typing import Dict, Union\n",
    "\n",
    "def hp_space(trial: Trial) -> Dict[str, Union[float, int, str]]:\n",
    "    return {\n",
    "        \"body_learning_rate\": trial.suggest_float(\"body_learning_rate\", 1e-6, 1e-3, log=True),\n",
    "        \"num_epochs\": trial.suggest_int(\"num_epochs\", 1, 3),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [16, 32, 64]),\n",
    "        \"seed\": trial.suggest_int(\"seed\", 1, 40),\n",
    "        \"max_iter\": trial.suggest_int(\"max_iter\", 50, 300),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"newton-cg\", \"lbfgs\", \"liblinear\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8098952-03fb-4755-86ef-740815b6f351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe71dbe800a4851bc083411360be725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-16 16:26:39,310] A new study created in memory with name: no-name-d32e5336-7b69-40f4-a98b-cb6e1d6d2ff4\n",
      "Trial: {'body_learning_rate': 0.0009800033214644025, 'num_epochs': 1, 'batch_size': 64, 'seed': 4, 'max_iter': 191, 'solver': 'newton-cg'}\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num unique pairs = 60222\n",
      "  Batch size = 64\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 941\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='941' max='941' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [941/941 08:42, Epoch 1/0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-10-16 16:35:26,385] Trial 0 finished with value: 0.8333333333333334 and parameters: {'body_learning_rate': 0.0009800033214644025, 'num_epochs': 1, 'batch_size': 64, 'seed': 4, 'max_iter': 191, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.8333333333333334.\n",
      "Trial: {'body_learning_rate': 5.860823205538936e-06, 'num_epochs': 2, 'batch_size': 32, 'seed': 3, 'max_iter': 164, 'solver': 'newton-cg'}\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num unique pairs = 60222\n",
      "  Batch size = 32\n",
      "  Num epochs = 2\n",
      "  Total optimization steps = 3764\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3764' max='3764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3764/3764 19:00, Epoch 2/0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-10-16 16:54:31,094] Trial 1 finished with value: 0.8205128205128205 and parameters: {'body_learning_rate': 5.860823205538936e-06, 'num_epochs': 2, 'batch_size': 32, 'seed': 3, 'max_iter': 164, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.8333333333333334.\n",
      "Trial: {'body_learning_rate': 0.00014785884631160625, 'num_epochs': 1, 'batch_size': 32, 'seed': 2, 'max_iter': 114, 'solver': 'liblinear'}\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num unique pairs = 60222\n",
      "  Batch size = 32\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 1882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1882' max='1882' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1882/1882 09:28, Epoch 1/0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-10-16 17:04:03,280] Trial 2 finished with value: 0.8205128205128205 and parameters: {'body_learning_rate': 0.00014785884631160625, 'num_epochs': 1, 'batch_size': 32, 'seed': 2, 'max_iter': 114, 'solver': 'liblinear'}. Best is trial 0 with value: 0.8333333333333334.\n",
      "Trial: {'body_learning_rate': 2.782848732335074e-06, 'num_epochs': 1, 'batch_size': 16, 'seed': 37, 'max_iter': 246, 'solver': 'lbfgs'}\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num unique pairs = 60222\n",
      "  Batch size = 16\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3764\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3764' max='3764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3764/3764 10:41, Epoch 1/0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-10-16 17:14:49,164] Trial 3 finished with value: 0.8205128205128205 and parameters: {'body_learning_rate': 2.782848732335074e-06, 'num_epochs': 1, 'batch_size': 16, 'seed': 37, 'max_iter': 246, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8333333333333334.\n",
      "Trial: {'body_learning_rate': 4.047590131223615e-05, 'num_epochs': 3, 'batch_size': 64, 'seed': 6, 'max_iter': 158, 'solver': 'lbfgs'}\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num unique pairs = 60222\n",
      "  Batch size = 64\n",
      "  Num epochs = 3\n",
      "  Total optimization steps = 2823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2823' max='2823' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2823/2823 26:23, Epoch 3/0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-10-16 17:41:17,168] Trial 4 finished with value: 0.8333333333333334 and parameters: {'body_learning_rate': 4.047590131223615e-05, 'num_epochs': 3, 'batch_size': 64, 'seed': 6, 'max_iter': 158, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8333333333333334.\n",
      "Trial: {'body_learning_rate': 1.4818154521353039e-06, 'num_epochs': 2, 'batch_size': 16, 'seed': 13, 'max_iter': 67, 'solver': 'liblinear'}\n",
      "/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num unique pairs = 60222\n",
      "  Batch size = 16\n",
      "  Num epochs = 2\n",
      "  Total optimization steps = 7528\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7267' max='7528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7267/7528 20:41 < 00:44, 5.85 it/s, Epoch 1.93/0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-16 18:02:01,871] Trial 5 failed with parameters: {'body_learning_rate': 1.4818154521353039e-06, 'num_epochs': 2, 'batch_size': 16, 'seed': 13, 'max_iter': 67, 'solver': 'liblinear'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/setfit/integrations.py\", line 27, in _objective\n",
      "    trainer.train(trial=trial)\n",
      "  File \"/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/setfit/trainer.py\", line 410, in train\n",
      "    self.train_embeddings(*full_parameters, args=args)\n",
      "  File \"/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/setfit/trainer.py\", line 462, in train_embeddings\n",
      "    self._train_sentence_transformer(\n",
      "  File \"/home/pricie/mfantoli/miniconda3/lib/python3.9/site-packages/setfit/trainer.py\", line 625, in _train_sentence_transformer\n",
      "    labels = labels.to(self.model.device)\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-16 18:02:01,880] Trial 5 failed with value None.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    train_dataset=balanced_caa['train'],\n",
    "    eval_dataset=balanced_caa['test'],\n",
    "    model_init=model_init,\n",
    ")\n",
    "best_run = trainer.hyperparameter_search(direction=\"maximize\", hp_space=hp_space, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5b128-45bc-4a77-adc3-70e69e520ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0450604c-c186-4f05-89c6-f80199943819",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2958636736.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    BestRun(run_id='8', objective=0.4785, hyperparameters={'body_learning_rate': 0.0005575631179396824, 'num_epochs': 1, 'batch_size': 32, 'seed': 31, 'max_iter': 264, 'solver': 'newton-cg'}, backend=<optuna.study.study.Study object at 0x000001E088B8C310>)\u001b[0m\n\u001b[0m                                                                                                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "BestRun(run_id='8', objective=0.4785, hyperparameters={'body_learning_rate': 0.0005575631179396824, 'num_epochs': 1, 'batch_size': 32, 'seed': 31, 'max_iter': 264, 'solver': 'newton-cg'}, backend=<optuna.study.study.Study object at 0x000001E088B8C310>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1f8bc8e-965c-4d19-afea-9a062ea73ecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mapply_hyperparameters(\u001b[43mbest_run\u001b[49m\u001b[38;5;241m.\u001b[39mhyperparameters, final_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_run' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437bd0da-e74f-4e34-a34f-79b1c19f3d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "/tmp/ipykernel_2251398/1262924370.py:5: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34934c0e48c74aa2845672305379d60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load SetFit model from Hub\n",
    "setfitmodel = SetFitModel.from_pretrained(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=setfitmodel,\n",
    "    train_dataset=balanced_caa['train'],\n",
    "    eval_dataset=balanced_caa['test'],\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=16,\n",
    "    num_iterations=20, # Number of text pairs to generate for contrastive learning\n",
    "    num_epochs=3 # Number of epochs to use for contrastive learning\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1f86c91-2cf1-4885-8ee2-7bb47c046351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 12320\n",
      "  Batch size = 16\n",
      "  Num epochs = 3\n",
      "  Total optimization steps = 2310\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 06:31, Epoch 3/0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a446b949-782f-4aeb-b356-1ccd3ea92e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = setfitmodel.predict(balanced_caa['test']['text'])\n",
    "\n",
    "preds = predictions.tolist()\n",
    "\n",
    "true = balanced_caa['test']['label']\n",
    "\n",
    "setfit_eval_results = classification_report(true, preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fb659f4-95df-4d43-9916-04cd100e51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested on ECCO\n",
    "\n",
    "predictions = setfitmodel.predict(ecco['test']['text'])\n",
    "preds = predictions.tolist()\n",
    "true = ecco['test']['label']\n",
    "\n",
    "setfit_ecco_eval_results = classification_report(true, preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9256641e-a9b7-41e4-acd7-8b808eba5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested on CAA\n",
    "\n",
    "predictions = setfitmodel.predict(caa['test']['text'])\n",
    "preds = predictions.tolist()\n",
    "true = caa['test']['label']\n",
    "\n",
    "setfit_caa_eval_results = classification_report(true, preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3db9705f-4a6f-4b22-8529-eb27e643ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested on combined\n",
    "\n",
    "predictions = setfitmodel.predict(combined['test']['text'])\n",
    "preds = predictions.tolist()\n",
    "true = combined['test']['label']\n",
    "\n",
    "setfit_combined_eval_results = classification_report(true, preds, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcd2757a-e733-4c64-adbe-3ec0d0e114bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DictName</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>0_precision</th>\n",
       "      <th>0_recall</th>\n",
       "      <th>0_f1-score</th>\n",
       "      <th>0_support</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_recall</th>\n",
       "      <th>1_f1-score</th>\n",
       "      <th>1_support</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>macro avg_support</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <th>weighted avg_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setfit_eval_results</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.903704</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.617460</td>\n",
       "      <td>0.642328</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.803175</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setfit_ecco_eval_results</td>\n",
       "      <td>0.487252</td>\n",
       "      <td>0.414239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585812</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.195556</td>\n",
       "      <td>0.327138</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.707120</td>\n",
       "      <td>0.597778</td>\n",
       "      <td>0.456475</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.787600</td>\n",
       "      <td>0.487252</td>\n",
       "      <td>0.420935</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setfit_caa_eval_results</td>\n",
       "      <td>0.956772</td>\n",
       "      <td>0.956710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977876</td>\n",
       "      <td>663.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.978355</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.520188</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.958644</td>\n",
       "      <td>0.956772</td>\n",
       "      <td>0.936988</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setfit_combined_eval_results</td>\n",
       "      <td>0.683761</td>\n",
       "      <td>0.669415</td>\n",
       "      <td>0.996652</td>\n",
       "      <td>0.800897</td>\n",
       "      <td>896.0</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.131890</td>\n",
       "      <td>0.231834</td>\n",
       "      <td>508.0</td>\n",
       "      <td>0.813279</td>\n",
       "      <td>0.564271</td>\n",
       "      <td>0.516365</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.773522</td>\n",
       "      <td>0.683761</td>\n",
       "      <td>0.594997</td>\n",
       "      <td>1404.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DictName  accuracy  0_precision  0_recall  0_f1-score  \\\n",
       "0           setfit_eval_results  0.833333     0.847222  0.968254    0.903704   \n",
       "1      setfit_ecco_eval_results  0.487252     0.414239  1.000000    0.585812   \n",
       "2       setfit_caa_eval_results  0.956772     0.956710  1.000000    0.977876   \n",
       "3  setfit_combined_eval_results  0.683761     0.669415  0.996652    0.800897   \n",
       "\n",
       "   0_support  1_precision  1_recall  1_f1-score  1_support  \\\n",
       "0       63.0     0.666667  0.266667    0.380952       15.0   \n",
       "1      128.0     1.000000  0.195556    0.327138      225.0   \n",
       "2      663.0     1.000000  0.032258    0.062500       31.0   \n",
       "3      896.0     0.957143  0.131890    0.231834      508.0   \n",
       "\n",
       "   macro avg_precision  macro avg_recall  macro avg_f1-score  \\\n",
       "0             0.756944          0.617460            0.642328   \n",
       "1             0.707120          0.597778            0.456475   \n",
       "2             0.978355          0.516129            0.520188   \n",
       "3             0.813279          0.564271            0.516365   \n",
       "\n",
       "   macro avg_support  weighted avg_precision  weighted avg_recall  \\\n",
       "0               78.0                0.812500             0.833333   \n",
       "1              353.0                0.787600             0.487252   \n",
       "2              694.0                0.958644             0.956772   \n",
       "3             1404.0                0.773522             0.683761   \n",
       "\n",
       "   weighted avg_f1-score  weighted avg_support  \n",
       "0               0.803175                  78.0  \n",
       "1               0.420935                 353.0  \n",
       "2               0.936988                 694.0  \n",
       "3               0.594997                1404.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_eval_results_dictionaries():\n",
    "    return {name: value for name, value in globals().items() if isinstance(value, dict) and 'eval_results' in name}\n",
    "\n",
    "eval_result_dictionaries = list_eval_results_dictionaries()\n",
    "\n",
    "dict_list = [{'DictName': name, ** eval_result_dictionaries[name]} for name in eval_result_dictionaries]\n",
    "\n",
    "dict_df = pd.DataFrame(dict_list)\n",
    "\n",
    "#dict_df = dict_df[['DictName'] + sorted(dict_df.columns.drop('DictName'),tolist())]\n",
    "\n",
    "\n",
    "def expand_dict_columns(df):\n",
    "    dict_columns = [col for col in df.columns if isinstance(df[col][0], dict)]\n",
    "    expanded_cols = []\n",
    "    for col in dict_columns:\n",
    "        expanded = pd.json_normalize(df[col])\n",
    "        expanded.columns = [f\"{col}_{key}\" for key in expanded.columns]\n",
    "        expanded_cols.append(expanded)\n",
    "    df = df.drop(columns=dict_columns)\n",
    "    if expanded_cols:\n",
    "        expanded_cols_df = pd.concat(expanded_cols, axis=1)\n",
    "        df = pd.concat([df, expanded_cols_df], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "dff = expand_dict_columns(dict_df)\n",
    "\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44541c77-3ce0-4445-a1cf-aba9c89ac19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv('../results/setfit-translation-task.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c49ac-350a-4c89-ad86-4cae162dcb96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
